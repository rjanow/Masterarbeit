{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGpxu4XY3JVZaFOwQM2hxB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/netCDF4_to_CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script um die netCDF4 Vorhersagewerte in einen Dataframe abzuspeichern"
      ],
      "metadata": {
        "id": "i2B2OHrSGmDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dokumentenname: netCDF4_to_CSV.ipynb**\n",
        "\n",
        "Es werden die Vorhersagedaten von CAMS aus dem netCDF4-Format in einen Dataframe umgewandelt."
      ],
      "metadata": {
        "id": "daD59hWqtJil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Allgemeine Einstelllungen:"
      ],
      "metadata": {
        "id": "JihVkTkbjiKN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s8BHga-2vKo",
        "outputId": "97f79270-1036-4172-8017-7c44695a05ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Installation der netCDF4 Bibliothek, da diese nicht standardmäßig in Google-Colab implementiert ist.\n",
        "!pip install netCDF4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import der benötigten Module und allgemeines Setup:"
      ],
      "metadata": {
        "id": "Cc71yyMstuWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der benötigten Module\n",
        "import os\n",
        "import pickle\n",
        "import netCDF4 as nc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aIT9A4pzVh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount der Google-Drive:"
      ],
      "metadata": {
        "id": "Mlo4MrUXt3vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mounten des Google-Drive Kontos\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2_FeYPA_Mfq",
        "outputId": "88a4d611-3901-4eac-c239-5267e1cba91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeit wird in Stunden seit 1.1.1900 00:00 angegeben\n",
        "origin = dt.datetime(1900, 1, 1, 0, 0, 0, 0)"
      ],
      "metadata": {
        "id": "WDT9g8r_LvX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive Ordner mit den Vorhersagewerten im NetCDF4-Format\n",
        "import_folder = '/content/drive/My Drive/Colab_Notebooks/netCDF4_Wetterdaten/'\n",
        "export_folder = '/content/drive/My Drive/Colab_Notebooks/CAMS_Vorhersage/'"
      ],
      "metadata": {
        "id": "pALUt9Lh_Q4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Einlesen der NetCDF4-Dateien:"
      ],
      "metadata": {
        "id": "mENI5XOei_ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nc_files_in_google_drive(folder_path):\n",
        "    nc_files = []  # Liste, um die NetCDF4-Datensätze abzuspeichern\n",
        "\n",
        "    if os.path.exists(folder_path):\n",
        "        # Durchsuchen des Drive-Ordners nach Dateien\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            # Überprüfen, ob die Datei eine NetCDF4-Datei ist\n",
        "            if file_name.endswith(\".nc\"):\n",
        "                try:\n",
        "                    # Öffnen der NetCDF4-Datei und huzfügen zur Liste\n",
        "                    nc_file = nc.Dataset(file_path)\n",
        "                    nc_files.append(nc_file)\n",
        "                    print(nc_file)\n",
        "                except Exception as e:\n",
        "                    print(f\"Fehler beim Öffnen von {file_name}: {str(e)}\")\n",
        "\n",
        "    return nc_files"
      ],
      "metadata": {
        "id": "raa9HC67BJ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funktionsaufruf zum Einlesen der NetCDF4-Dateien\n",
        "netcdf_files = read_nc_files_in_google_drive(import_folder)"
      ],
      "metadata": {
        "id": "qjoiyX9ABN9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# netcdf_files"
      ],
      "metadata": {
        "id": "60XudhcPW65D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variablen Deklaration:"
      ],
      "metadata": {
        "id": "F54mh2H2uNjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variablen Deklaration\n",
        "latitudes = np.empty((1, 1))\n",
        "longitudes = np.empty((1, 1))\n",
        "time = np.empty((1, 1))\n",
        "aod469 = np.empty((1, 1))   # Aerosol Optical Depth at 469\n",
        "aod550 = np.empty((1, 1))   # Aerosol Optical Depth at 550\n",
        "gtco3 = np.empty((1, 1))    # Total Ozon Column\n",
        "uvbed = np.empty((1, 1))    # UVI All-Sky\n",
        "uvbedcs = np.empty((1, 1))  # UVI Clear-Sky\n",
        "hcc = np.empty((1, 1))      # High-Cloud-Cover\n",
        "lcc = np.empty((1, 1))      # Low-Cloud-Cover\n",
        "tcc = np.empty((1, 1))      # Total-Cloud-Cover\n",
        "# neu\n",
        "tp = np.empty((1, 1))       # Total Precipitation\n",
        "d2m = np.empty((1, 1))      # 2 Metre Dewpoint Temperature\n",
        "t2m = np.empty((1, 1))      # 2 Metre Temperature\n",
        "sund = np.empty((1, 1))     # Sunshine Duration\n",
        "ssrd = np.empty((1, 1))     # Surface Solar Radiation Downwards"
      ],
      "metadata": {
        "id": "UoEl-3yuEr3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zuordnen der Variabeln zu entsprechenden NP-Arrays\n",
        "# fehlende Werte werden durch NaN Werte ersetzt, das mehrdimensionale Array wird zu einem eindimensonalen formatiert\n",
        "\n",
        "for nc_file in netcdf_files:\n",
        "    latitudes = np.append(latitudes, nc_file.variables['latitude'][0])\n",
        "    longitudes = np.append(longitudes, nc_file.variables['longitude'][0])\n",
        "    time = np.append(time, nc_file.variables['time'][:].filled(np.nan))\n",
        "    aod469 = np.append(aod469, nc_file.variables['aod469'][:].filled(np.nan).reshape(-3))\n",
        "    aod550 = np.append(aod550, nc_file.variables['aod550'][:].filled(np.nan).reshape(-3))\n",
        "    gtco3 = np.append(gtco3, nc_file.variables['gtco3'][:].filled(np.nan).reshape(-3))\n",
        "    uvbed = np.append(uvbed, nc_file.variables['uvbed'][:].filled(np.nan).reshape(-3))\n",
        "    uvbedcs = np.append(uvbedcs, nc_file.variables['uvbedcs'][:].filled(np.nan).reshape(-3))\n",
        "    hcc = np.append(hcc, nc_file.variables['hcc'][:].filled(np.nan).reshape(-3))\n",
        "    lcc = np.append(lcc, nc_file.variables['lcc'][:].filled(np.nan).reshape(-3))\n",
        "    tcc = np.append(tcc, nc_file.variables['tcc'][:].filled(np.nan).reshape(-3))\n",
        "    # neu\n",
        "    tp = np.append(uvbedcs, nc_file.variables['tp'][:].filled(np.nan).reshape(-3))\n",
        "    d2m = np.append(hcc, nc_file.variables['d2m'][:].filled(np.nan).reshape(-3))\n",
        "    t2m = np.append(lcc, nc_file.variables['t2m'][:].filled(np.nan).reshape(-3))\n",
        "    sund = np.append(tcc, nc_file.variables['sund'][:].filled(np.nan).reshape(-3))\n",
        "    ssrd = np.append(tcc, nc_file.variables['ssrd'][:].filled(np.nan).reshape(-3))"
      ],
      "metadata": {
        "id": "WpEhJuiYGKJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Größe der verschiedenen Datensätze\n",
        "print(len(time), len(aod469), len(aod550), len(uvbed), len(uvbedcs), len(hcc), len(lcc), len(tcc), len(tp), len(d2m), len(t2m), len(sund), len(ssrd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FxwLLuggWMF",
        "outputId": "20ccbf39-9668-4329-a94d-0775124ed5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10225 10225 10225 10225 10225 10225 10225 10225 10945 10945 10945 10945 10945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Berechnen der richtigen DateTime-Werte und erstellen eines Dataframes:"
      ],
      "metadata": {
        "id": "r8P4Gg-rufVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# richtigen Zeitstempel berechnen\n",
        "datetime = np.empty((1,1))\n",
        "datetime = np.array([origin + dt.timedelta(hours=int(i)) for i in time])"
      ],
      "metadata": {
        "id": "V8Sfh_WRC5pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zuorden der NP-Arrays in einen Dataframe\n",
        "df_cams = pd.DataFrame({'Datetime': datetime, 'aod469': aod469, 'aod550': aod550, 'gtco3': gtco3,\n",
        "                         'uvbed': uvbed,'uvbedcs': uvbedcs, 'hcc': hcc, 'lcc': lcc, 'mcc': mcc, 'tcc': tcc, 'cbh': cbh})"
      ],
      "metadata": {
        "id": "PdvXQnQBULsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UV-Index berechnen\n",
        "df_cams['uvbed'] = df_cams['uvbed'] * 40\n",
        "df_cams['uvbedcs'] = df_cams['uvbedcs'] * 40"
      ],
      "metadata": {
        "id": "IV3PuyvhT7gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeitstempel in Pandas-DateTime umwandeln\n",
        "df_cams['Datetime'] = pd.to_datetime(df_cams['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
        "# Index des DF setzen\n",
        "df_cams.set_index('Datetime', inplace=True)"
      ],
      "metadata": {
        "id": "a2ZkgFNvmks9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sontieren des DataFrame in die richtige Reihenfolge\n",
        "df_cams_sorted = pd.DataFrame()\n",
        "df_cams_sorted = df_cams.sort_index().drop(df_cams.index[0])"
      ],
      "metadata": {
        "id": "iayKm6uoF_B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ausgabe des sotierten Dataframes\n",
        "df_cams_sorted"
      ],
      "metadata": {
        "id": "PyHPpi-tLZKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prüfen, ob der Dataframe alle Einträge enthält:"
      ],
      "metadata": {
        "id": "XaRfKKbmndO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prüfen, ob der Dataframe alle Einträge enthält\n",
        "for i in range(len(df_cams_sorted) - 1):\n",
        "    time_diff = df_cams_sorted.index[i + 1] - df_cams_sorted.index[i]\n",
        "    if time_diff != pd.to_timedelta('1H'):\n",
        "        print(f\"Index {i} und Index {i + 1} haben keinen Abstand von einer Stunde.\")"
      ],
      "metadata": {
        "id": "hJIvtXFbL4Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abspeichern des Dataframes mit stündlicher Auflösung:"
      ],
      "metadata": {
        "id": "zjKvaqw4jU0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe_to_drive(dataframe, folder_path, filename):\n",
        "\n",
        "    # Erstellen des vollen Pfades zur Datei\n",
        "    full_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Speichern des DataFrame als CSV-Datei auf Google-Drive\n",
        "    dataframe.to_csv(full_path)\n",
        "\n",
        "    print(f'Der DataFrame wurde als {filename} in {folder_path} auf Google Drive gespeichert.')"
      ],
      "metadata": {
        "id": "38Mwi6sJDihp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abspeichern des konvertierten DF als CSV\n",
        "dateiname = 'CSV_Cams_std'\n",
        "save_dataframe_to_drive(df_cams_sorted, import_folder, dateiname)"
      ],
      "metadata": {
        "id": "d7XCZUzEDAz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abspeichern des Dataframes mit 2 Min. Auflösung."
      ],
      "metadata": {
        "id": "yAPYiqb-kVdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling der Zeitreihe auf 2 Min. und interpolation der fehlenden Messwerte\n",
        "# df_cams_resampled = df_cams.resample('2T')\n",
        "# df_cams_interpolated = df_cams_resampled.interpolate(method='polynomial', order = 1)"
      ],
      "metadata": {
        "id": "ZZC3q3n-IUv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abspeichern des konvertierten DF als CSV\n",
        "# dateiname = 'CSV_Cams_2M'\n",
        "# save_dataframe_to_drive(df_cams_interpolated, '/content/drive/My Drive/Colab_Notebooks/CSV_Vorhersage', dateiname)"
      ],
      "metadata": {
        "id": "TFwR_uY4khMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dateiname = 'pickle_Cams_2M'\n",
        "# df_cams_interpolated.to_pickle(pickle_path + dateiname)"
      ],
      "metadata": {
        "id": "iNQTyRwF0Ff6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}