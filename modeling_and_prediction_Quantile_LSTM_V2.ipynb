{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "modeling_and_prediction_Quantile_LSTM.ipynb",
      "authorship_tag": "ABX9TyMmoQawjhdOnHwpucyelzfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/modeling_and_prediction_Quantile_LSTM_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM BASELINE MODEL"
      ],
      "metadata": {
        "id": "0Ng7WlqRF6Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Skript wird ein erstes Modell erzeugt, um aus den gemssenen Globalstrahlungsdaten den UVI zu berechen."
      ],
      "metadata": {
        "id": "AsUt2K5PFuQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbinden mit der Google-Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN5x7YhZ99QP",
        "outputId": "7aa8159d-0ca9-4c71-8827-baad345762a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XgnNp1CjFzPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSK4Ns8Op4YG",
        "outputId": "56ad8fb3-a508-40ea-d57a-7a2c60e01c82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Input\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "L1rcvDzU-F-w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funktionen:"
      ],
      "metadata": {
        "id": "KwH3fCP0Y-F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sMAPE Funktion zum brechnen des symmetric mean absolute percentage error\n",
        "def smape(y_true, y_pred):\n",
        "    diff = K.abs(y_true - y_pred)\n",
        "    denom = K.abs(y_true) + K.abs(y_pred)\n",
        "    return 200.0 * K.mean(diff / (denom + K.epsilon()))"
      ],
      "metadata": {
        "id": "VfGh4u0ULVkV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "o4-tDR37Y9dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zur CSV-Datei auf Google-Drive\n",
        "name_Messwerte = 'Messdaten_CAMS_GHI.csv'\n",
        "name_Vorhersage = 'Vorhersagedaten_CAMS_VarIdx.csv'\n",
        "folder_import = '/content/drive/My Drive/Colab_Notebooks/Clean_Data/'"
      ],
      "metadata": {
        "id": "yBFyA7hw9-XT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zum Abspeichern des trainierten Modells in Google-Drive\n",
        "\n",
        "model_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/full_model.keras'\n",
        "weights_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_weights.weights.h5'\n",
        "\n",
        "# Pfad für den Testdatensatz\n",
        "\n",
        "testdata_path_X = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_testdata_X.csv'\n",
        "testdata_path_Y = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_testdata_Y.csv'\n",
        "\n",
        "# Pfad für die Logdatei\n",
        "\n",
        "text_file_path = \"/content/drive/MyDrive/Colab_Notebooks/LSTM_Model/model_results.txt\""
      ],
      "metadata": {
        "id": "d0Cj9p-p5yu2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Messdaten\n",
        "df_Messdaten = pd.read_csv(folder_import + name_Messwerte)"
      ],
      "metadata": {
        "id": "1RAsBy3qGHTE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Vorhersagedaten\n",
        "df_Vorhersage = pd.read_csv(folder_import + name_Vorhersage)"
      ],
      "metadata": {
        "id": "t1qhUxgIUU3v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konvertiere die Zeitspalten in ein gemeinsames Format und führe einen Merge der Datensätze durch\n",
        "df_Messdaten['Datetime'] = pd.to_datetime(df_Messdaten['Datetime'])\n",
        "df_Vorhersage['Datetime'] = pd.to_datetime(df_Vorhersage['Datetime'])"
      ],
      "metadata": {
        "id": "ETDBeb_894PE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spalten in den Messdaten\n",
        "df_Messdaten.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCdeBkhdUqUJ",
        "outputId": "c657c109-a7a6-4dea-edf0-84eacb8c622e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Datetime', 'Observation_period', 'Clear_sky_GHI', 'Clear_sky_BHI',\n",
              "       'GHI', 'BHI', 'UVI', 'UVA', 'UVB', 'erythem', 'Datum', 'Uhrzeit',\n",
              "       'Messzeitpunkt', 'ghi', 'Dif', 'Glo_SPLite', 'Dir', 'Temp',\n",
              "       'DiffGreater2', 'SZA', 'time_sin', 'time_cos', 'date_sin', 'date_cos',\n",
              "       'Date', 'Hour'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funktionsdefinition:"
      ],
      "metadata": {
        "id": "gVL5jtI6xY1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantile_loss(q, y_true, y_pred):\n",
        "    \"\"\"Berechnet den Pinball Loss für mehrere Quantile.\"\"\"\n",
        "    e = y_true - y_pred\n",
        "    return tf.reduce_mean(tf.maximum(q * e, (q - 1) * e), axis=-1)  # Reduziere entlang der letzten Achse"
      ],
      "metadata": {
        "id": "r03jEf38xg0z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_quantile_loss(y_true, y_pred):\n",
        "    \"\"\"Berechnet den Gesamt-Quantile-Loss für alle Quantile.\"\"\"\n",
        "    losses = [quantile_loss(q, y_true[:, i], y_pred[:, i]) for i, q in enumerate(quantiles)]\n",
        "    return tf.reduce_mean(losses)  # Mittelwert über alle Quantile"
      ],
      "metadata": {
        "id": "ekmhYIqUsqxk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "xju0lfd5awtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"LSTM_mit_Vorhersagewerten_1Step\""
      ],
      "metadata": {
        "id": "6Zy9MKrucOM7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispiel: Nur 'SZA' als Feature und 'UVI' als Label\n",
        "columns_X = ['Clear_sky_GHI', 'Clear_sky_BHI', 'GHI', 'BHI', 'Temp', 'SZA', 'time_sin', 'time_cos', 'date_sin', 'date_cos']\n",
        "columns_y = ['UVI']"
      ],
      "metadata": {
        "id": "aJvSqJ6Q0Mh0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]"
      ],
      "metadata": {
        "id": "GBQa5_j2sN2F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"units_1\": 64,\n",
        "    \"units_2\": 32,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"final_activation\": \"linear\"\n",
        "}"
      ],
      "metadata": {
        "id": "rAe1lsV6Y7EB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_config = {\n",
        "    \"loss\": multi_quantile_loss,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"metrics\": [\n",
        "        \"mse\",\n",
        "        \"mae\",\n",
        "        \"mape\",\n",
        "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "hhLV4E0Va0O_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_config = {\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 32,\n",
        "    \"sequence_length\": 16\n",
        "}"
      ],
      "metadata": {
        "id": "kBhkV9jkQHS8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Q3cZJrysZFmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_Messdaten.copy()  # deine Messdaten\n",
        "\n",
        "total_length = len(df)\n",
        "train_size   = round(total_length * 0.80)\n",
        "val_size     = round(total_length * 0.10)\n",
        "test_size    = total_length - train_size - val_size  # restliche 10%\n",
        "\n",
        "# Skaliere X und Y separat (immer zuerst nur auf dem Trainingsbereich fitten!)\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# 1) Nur Trainingsdatensatz extrahieren\n",
        "train_df = df.iloc[:train_size]\n",
        "# Fit des Scalers NUR auf Trainingsdaten\n",
        "train_df[columns_X] = scaler_X.fit_transform(train_df[columns_X])\n",
        "train_df[columns_y] = scaler_y.fit_transform(train_df[columns_y])\n",
        "\n",
        "# 2) Für Validation\n",
        "val_df = df.iloc[train_size : train_size + val_size].copy()\n",
        "val_df[columns_X] = scaler_X.transform(val_df[columns_X])\n",
        "val_df[columns_y] = scaler_y.transform(val_df[columns_y])\n",
        "\n",
        "# 3) Für Test\n",
        "test_df = df.iloc[train_size + val_size :].copy()\n",
        "test_df[columns_X] = scaler_X.transform(test_df[columns_X])\n",
        "test_df[columns_y] = scaler_y.transform(test_df[columns_y])\n",
        "\n",
        "# Kontrolle\n",
        "print(\"Train:\", train_df.shape)\n",
        "print(\"Val:\", val_df.shape)\n",
        "print(\"Test:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArmMIX9h0zAO",
        "outputId": "28185b18-aa39-4b8b-9c72-3508027543bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (77386, 26)\n",
            "Val: (9673, 26)\n",
            "Test: (9673, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-76f70d0c4b52>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df[columns_X] = scaler_X.fit_transform(train_df[columns_X])\n",
            "<ipython-input-21-76f70d0c4b52>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df[columns_y] = scaler_y.fit_transform(train_df[columns_y])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence(X, y, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for stop_idx in range(seq_length, len(X)):\n",
        "        x_seq = X.iloc[stop_idx-seq_length:stop_idx].values  # (seq_length, num_features)\n",
        "        y_label = y.iloc[stop_idx]                           # Wert am Zeitpunkt 'stop_idx'\n",
        "        sequences.append(x_seq)\n",
        "        labels.append(y_label)\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "Bgzb01Gy01MY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_OneStepAhead(X, y, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    # bis len(X)-1, damit \"stop_idx + 1\" nicht out-of-range ist\n",
        "    for stop_idx in range(seq_length, len(X)-1):\n",
        "        x_seq = X.iloc[stop_idx-seq_length:stop_idx].values\n",
        "        y_label = y.iloc[stop_idx + 1]  # => label ist der nächste Zeitschritt\n",
        "        sequences.append(x_seq)\n",
        "        labels.append(y_label)\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "1BCYvGNv03yO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = fit_config[\"sequence_length\"]\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequence_OneStepAhead(train_df[columns_X], train_df[columns_y], sequence_len)\n",
        "X_val_seq,   y_val_seq   = create_sequence_OneStepAhead(val_df[columns_X],   val_df[columns_y],   sequence_len)\n",
        "X_test_seq,  y_test_seq  = create_sequence_OneStepAhead(test_df[columns_X],  test_df[columns_y],  sequence_len)\n",
        "\n",
        "y_train_seq = np.tile(y_train_seq, (1, len(quantiles)))  # (77369, 5)\n",
        "y_val_seq   = np.tile(y_val_seq, (1, len(quantiles)))\n",
        "y_test_seq  = np.tile(y_test_seq, (1, len(quantiles)))\n",
        "\n",
        "print(\"X_train_seq:\", X_train_seq.shape, \"y_train_seq:\", y_train_seq.shape)\n",
        "print(\"X_val_seq:\", X_val_seq.shape,\"y_val_seq:\", y_val_seq.shape)\n",
        "print(\"X_test_seq:\", X_test_seq.shape,\"y_test_seq:\",  y_test_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uSG1jbc0-28",
        "outputId": "bca65cf3-a727-4376-d7e1-c18845a5e49a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_seq: (77369, 16, 10) y_train_seq: (77369, 5)\n",
            "X_val_seq: (9656, 16, 10) y_val_seq: (9656, 5)\n",
            "X_test_seq: (9656, 16, 10) y_test_seq: (9656, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_2D = pd.DataFrame(X_test_seq.reshape(9656, -1))\n",
        "y_test_2D = pd.DataFrame(y_test_seq.reshape(9656, -1))"
      ],
      "metadata": {
        "id": "KGCmmBdje9zn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# abspeichern der Testdaten in der Google-Drive\n",
        "X_test_2D.to_csv(testdata_path_X, index = False)\n",
        "y_test_2D.to_csv(testdata_path_Y, index = False)"
      ],
      "metadata": {
        "id": "R6eWUcFLd169"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (16, 1)"
      ],
      "metadata": {
        "id": "SxZJ0UsZ1BYX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_compile_model(model_config, training_config, input_shape):\n",
        "\n",
        "    # 1) Input-Schicht\n",
        "    inputs = Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    # 2) Gemeinsame LSTM-Layer (Feature Extraktion)\n",
        "    x = LSTM(units=model_config[\"units_1\"], return_sequences=True)(inputs)\n",
        "    x = Dropout(model_config[\"dropout_rate\"])(x)\n",
        "\n",
        "    x = LSTM(units=model_config[\"units_2\"], return_sequences=False)(x)\n",
        "    x = Dropout(model_config[\"dropout_rate\"])(x)\n",
        "\n",
        "    # 3) Separate Heads für jedes Quantil\n",
        "    #    Jeder Head ist eine Dense-Schicht mit 1 Neuron\n",
        "    q10 = Dense(1, activation=model_config[\"final_activation\"], name=\"q10\")(x)\n",
        "    q25 = Dense(1, activation=model_config[\"final_activation\"], name=\"q25\")(x)\n",
        "    q50 = Dense(1, activation=model_config[\"final_activation\"], name=\"q50\")(x)\n",
        "    q75 = Dense(1, activation=model_config[\"final_activation\"], name=\"q75\")(x)\n",
        "    q90 = Dense(1, activation=model_config[\"final_activation\"], name=\"q90\")(x)\n",
        "\n",
        "    # 4) Modell definieren: Ein Input, fünf parallele Outputs\n",
        "    model = Model(inputs=inputs, outputs=[q10, q25, q50, q75, q90], name=\"quantile_lstm_model\")\n",
        "\n",
        "    # 5) Kompilieren: training_config muss eine Multi-Output-Loss-Definition enthalten\n",
        "    model.compile(**training_config)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "83_IF4a7Vt1S"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])  # z.B. (16, 1)\n",
        "\n",
        "model = build_and_compile_model(\n",
        "    model_config=model_config,\n",
        "    training_config=training_config,\n",
        "    input_shape=input_shape\n",
        ")"
      ],
      "metadata": {
        "id": "x6MQPmZ2bTQM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "phbmsVsX-qW_",
        "outputId": "b3e42152-0027-4e3a-bd85-7744f8669715"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"quantile_lstm_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"quantile_lstm_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m19,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m12,416\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q10 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q25 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q50 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q75 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q90 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m33\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ q90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,781\u001b[0m (124.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,781</span> (124.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,781\u001b[0m (124.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,781</span> (124.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    validation_data=(X_val_seq, y_val_seq),\n",
        "    epochs=fit_config[\"epochs\"],\n",
        "    batch_size=fit_config[\"batch_size\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ln2ZkEBrkxY6",
        "outputId": "00cd6242-7fbc-45d8-9f84-f6fefdbbdc11"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"The path: (0,) in the `loss` argument, can't be found in either the model's output (`y_pred`) or in the labels (`y_true`).\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8ead9f7bf4f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\u001b[0m in \u001b[0;36m_build_nested\u001b[0;34m(self, y_true, y_pred, loss, output_names, current_path)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey_check_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m    554\u001b[0m                     \u001b[0;34mf\"The path: {current_path + (key,)} in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"the `loss` argument, can't be found in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"The path: (0,) in the `loss` argument, can't be found in either the model's output (`y_pred`) or in the labels (`y_true`).\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechnen des vorhergesagten UVI\n",
        "y_pred = model.predict(X_test_seq)"
      ],
      "metadata": {
        "id": "4bxULDGoGp92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_seq.shape, y_pred.shape)"
      ],
      "metadata": {
        "id": "nGIF6xOr5tzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Evaluieren (Keras-integrierte Metriken)\n",
        "val_results = model.evaluate(X_val_seq, y_val_seq, verbose=0)\n",
        "test_results = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
        "print(\"Model metrics names:\", model.metrics_names)\n",
        "\n",
        "y_val_pred = model.predict(X_val_seq)  # Shape: (9656, 5)\n",
        "y_test_pred = model.predict(X_test_seq)\n",
        "\n",
        "# 50%-Quantil aus den Vorhersagen extrahieren\n",
        "y_val_pred_median = y_val_pred[:, 2]  # Index 2 = 50%-Quantil\n",
        "y_test_pred_median = y_test_pred[:, 2]\n",
        "\n",
        "if y_val_seq.shape[1] == 5:\n",
        "    y_val_seq = y_val_seq[:, 0]  # Verwende nur die echte UV-Strahlung\n",
        "    y_test_seq = y_test_seq[:, 0]\n",
        "\n",
        "# R²-Score berechnen\n",
        "val_r2  = r2_score(y_val_seq, y_val_pred_median)\n",
        "test_r2 = r2_score(y_test_seq, y_test_pred_median)\n",
        "\n",
        "# 4) Dictionary bauen\n",
        "metrics = {\n",
        "    \"val_loss\": val_results[0],\n",
        "    \"val_mse\":  val_results[1],\n",
        "    \"val_mae\":  val_results[2],\n",
        "    \"val_rmse\": val_results[3],\n",
        "    \"test_loss\": test_results[0],\n",
        "    \"test_mse\":  test_results[1],\n",
        "    \"test_mae\":  test_results[2],\n",
        "    \"test_rmse\": test_results[3],\n",
        "    \"val_r2\": val_r2,\n",
        "    \"test_r2\": test_r2\n",
        "}"
      ],
      "metadata": {
        "id": "Ys86VBr57sQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_val_seq shape:\", y_val_seq.shape)  # Erwartet: (9656, 1) oder (9656,)\n",
        "print(\"y_val_pred_median shape:\", y_val_pred_median.shape)  # Erwartet: (9656,)"
      ],
      "metadata": {
        "id": "HIHlIvL8hli0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.flatten()\n",
        "y_test_seq = y_test_seq.flatten()"
      ],
      "metadata": {
        "id": "TjK_j366Dvc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_pred)"
      ],
      "metadata": {
        "id": "x5LAKe82EFa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Püfen, ob die Vorhersage den selben Shape hat wie\n",
        "print(y_pred.shape, y_test_seq.shape)"
      ],
      "metadata": {
        "id": "x5qP8JayLkjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abspeichern des trainierten Modells und der Gewichte\n",
        "\n",
        "model.save(model_path)\n",
        "model.save_weights(weights_path)\n",
        "\n",
        "# Abspeichern des Testdatensatzes für eine spätere Auswertung"
      ],
      "metadata": {
        "id": "6X_QA6DJ5rXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Berechnung der Qualitätsparameter:"
      ],
      "metadata": {
        "id": "GKskVQkk7Wiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_model_output(model, X_test, y_test, output_indices=None, plot_indices=None):\n",
        "    \"\"\"\n",
        "    Vergleicht die tatsächlichen Werte mit den vorhergesagten Werten für beliebige Output-Features.\n",
        "    Plottet die Werte und berechnet Metriken.\n",
        "\n",
        "    Parameter:\n",
        "    - model: Trainiertes Keras-Modell\n",
        "    - X_test: Test-Daten für Eingabe (Shape: (Anzahl, Timesteps, Features))\n",
        "    - y_test: Tatsächliche Werte (Shape: (Anzahl, Output_Features) oder (Anzahl,))\n",
        "    - output_indices: Liste der Output-Indizes, die ausgewertet werden sollen (z.B. [2] für das 50%-Quantil)\n",
        "                      Falls None, werden alle Outputs verwendet.\n",
        "    - plot_indices: Optionaler Tupel (start, end), um Detailplots für einen bestimmten Bereich zu zeigen.\n",
        "    \"\"\"\n",
        "\n",
        "    # Vorhersage berechnen (Shape: (Anzahl, Output_Features))\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Falls keine spezifischen Output-Indices angegeben sind, alle nehmen\n",
        "    if output_indices is None:\n",
        "        output_indices = list(range(y_pred.shape[1]))  # Alle Spalten\n",
        "\n",
        "    # Falls y_test mehrdimensional ist, nur die relevanten Spalten auswählen\n",
        "    if y_test.ndim == 2 and y_test.shape[1] > 1:\n",
        "        y_test = y_test[:, 0]  # Nur die echte Zielvariable verwenden\n",
        "\n",
        "    # Metriken für jeden gewählten Output berechnen\n",
        "    mse_values = []\n",
        "    mae_values = []\n",
        "    for idx in output_indices:\n",
        "        mse = mean_squared_error(y_test, y_pred[:, idx])\n",
        "        mae = mean_absolute_error(y_test, y_pred[:, idx])\n",
        "        mse_values.append(mse)\n",
        "        mae_values.append(mae)\n",
        "        print(f\"Feature {idx}: MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
        "\n",
        "    # Gesamten Vergleich plotten\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for idx in output_indices:\n",
        "        plt.plot(y_pred[:, idx], label=f'Vorhersage (Feature {idx})', alpha=0.7)\n",
        "    plt.plot(y_test, label='Tatsächlicher Wert', alpha=0.7, linestyle='dashed', color='black')\n",
        "    plt.title('Vergleich Vorhersage vs. Tatsächlicher Wert')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Optionaler Detailplot für einen bestimmten Indexbereich\n",
        "    if plot_indices is not None:\n",
        "        start, end = plot_indices\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        for idx in output_indices:\n",
        "            plt.plot(np.arange(start, end), y_pred[start:end, idx], label=f'Vorhersage (Feature {idx})', alpha=0.7)\n",
        "        plt.plot(np.arange(start, end), y_test[start:end], label='Tatsächlicher Wert', alpha=0.7, linestyle='dashed', color='black')\n",
        "        plt.title(f'Detailplot (Index {start} - {end})')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "C3AP07dK-b1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funktion aufrufen\n",
        "compare_model_output(model, X_test_seq, y_test_seq, output_indices=[0, 1, 2, 3, 4], plot_indices=(5700, 6150))  # Mehrere Quantile vergleichen"
      ],
      "metadata": {
        "id": "ZL4b3_wP-v0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_model_output(model, X_test_seq[200:675], y_test_seq[200:675], output_indices=[0, 1, 2, 3, 4], plot_indices=(0, 200))  # Mehrere Quantile vergleichen"
      ],
      "metadata": {
        "id": "w_bEh_WSFAGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_quantile_violations(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Berechnet, wie oft die gemessenen Werte (y_true)\n",
        "    das 10%- und 25%-Quantil unterschreiten sowie\n",
        "    das 75%- und 90%-Quantil überschreiten. Zusätzlich\n",
        "    wird der prozentuale Anteil dieser Verletzungen\n",
        "    (bezogen auf alle Datenpunkte) ausgegeben.\n",
        "\n",
        "    Parameter:\n",
        "    ----------\n",
        "    y_true : numpy.ndarray\n",
        "        1D-Array mit den tatsächlichen Messwerten (Form: (N,))\n",
        "    y_pred : numpy.ndarray\n",
        "        2D-Array der vorhergesagten Quantile (Form: (N, 5)).\n",
        "        Spalten: [10%-Quantil, 25%-Quantil, 50%-Quantil, 75%-Quantil, 90%-Quantil]\n",
        "\n",
        "    Rückgabe:\n",
        "    ----------\n",
        "    dict\n",
        "        Dictionary mit absoluten Anzahlen und prozentualen Anteilen.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(y_true)  # Gesamtzahl der Datenpunkte\n",
        "\n",
        "    # Absolutzahlen für Verletzungen berechnen\n",
        "    below_10p = np.sum(y_true < y_pred[:, 0])\n",
        "    below_25p = np.sum(y_true < y_pred[:, 1])\n",
        "    above_75p = np.sum(y_true > y_pred[:, 3])\n",
        "    above_90p = np.sum(y_true > y_pred[:, 4])\n",
        "\n",
        "    # Prozentsätze berechnen\n",
        "    below_10p_pct = (below_10p / n) * 100\n",
        "    below_25p_pct = (below_25p / n) * 100\n",
        "    above_75p_pct = (above_75p / n) * 100\n",
        "    above_90p_pct = (above_90p / n) * 100\n",
        "\n",
        "    return {\n",
        "        'below_10_percentile': {\n",
        "            'count': below_10p,\n",
        "            'percentage': below_10p_pct\n",
        "        },\n",
        "        'below_25_percentile': {\n",
        "            'count': below_25p,\n",
        "            'percentage': below_25p_pct\n",
        "        },\n",
        "        'above_75_percentile': {\n",
        "            'count': above_75p,\n",
        "            'percentage': above_75p_pct\n",
        "        },\n",
        "        'above_90_percentile': {\n",
        "            'count': above_90p,\n",
        "            'percentage': above_90p_pct\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "Lukxi48aPmzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = check_quantile_violations(y_test_seq, model.predict(X_test_seq))"
      ],
      "metadata": {
        "id": "2x8uocn9PntG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "4Z7kur9qQwfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_model_results_to_csv(\n",
        "    model_name,\n",
        "    model_config,        # Dictionary mit Modell-Hyperparametern\n",
        "    training_config,     # Dictionary mit Compile-Einstellungen (model.compile)\n",
        "    fit_config,          # <--- NEU: Dictionary mit fit-Parametern (epochs, batch_size, sequence_length)\n",
        "    metrics,             # Dictionary mit erzielten Metriken\n",
        "    csv_path=\"model_results.csv\"\n",
        "):\n",
        "\n",
        "    # 1) Zusammenführen aller Informationen in ein Dictionary\n",
        "    results_dict = {\n",
        "        \"model_name\": model_name\n",
        "    }\n",
        "\n",
        "    # Modell-Konfigurationswerte hinzufügen\n",
        "    for k, v in model_config.items():\n",
        "        results_dict[f\"model_config.{k}\"] = v\n",
        "\n",
        "    # Trainings-Konfigurationswerte (compile) hinzufügen\n",
        "    for k, v in training_config.items():\n",
        "        results_dict[f\"training_config.{k}\"] = str(v)\n",
        "\n",
        "    # Fit-Konfigurationswerte (fit) hinzufügen\n",
        "    for k, v in fit_config.items():\n",
        "        results_dict[f\"fit_config.{k}\"] = v\n",
        "\n",
        "    # Metrics hinzufügen\n",
        "    results_dict.update(metrics)\n",
        "\n",
        "    # 2) Anzeige in der Konsole\n",
        "    print(\"=== Model Results ===\")\n",
        "    for key, value in results_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(\"======================\\n\")\n",
        "\n",
        "    # 3) In einen DataFrame umwandeln (eine Zeile pro Modell)\n",
        "    df_results = pd.DataFrame([results_dict])\n",
        "\n",
        "    # 4) Schreiben oder Anhängen in die CSV\n",
        "    if not os.path.exists(csv_path):\n",
        "        df_results.to_csv(csv_path, index=False)\n",
        "    else:\n",
        "        df_results.to_csv(csv_path, mode='a', index=False, header=False)"
      ],
      "metadata": {
        "id": "X_W2T60755eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])"
      ],
      "metadata": {
        "id": "RJep2McgXp1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model_results_to_csv(\n",
        "    model_name=model_name,\n",
        "    model_config=model_config,\n",
        "    training_config=training_config,\n",
        "    fit_config=fit_config,        # <--- Neues Argument\n",
        "    metrics=metrics,\n",
        "    csv_path=\"model_results.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "HNul4aLxXs4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLT4kI7S3KXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}