{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXYH8GtObsOzrR/oQRq85n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/UV_Measurement_to_CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hier werden die Rohdaten des BTS2048-UV-WP in eine nutzbare CSV-Datei geschrieben**"
      ],
      "metadata": {
        "id": "VbXcbReNyuop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dokumentenname: UV_Measurement_to_CSV.ipynb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Es werden die OR0-Daten (NasaAmes-Format), die eigentlich für den Versand an das BFS gedacht sind umgewandelt und in eine CSV-Datei geschrieben."
      ],
      "metadata": {
        "id": "_Euu6x1XyxGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der benötigten Module\n",
        "import os, sys\n",
        "import glob\n",
        "import json\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "\n",
        "from scipy.io import netcdf\n",
        "from datetime import timedelta\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "6GGZwyBJzVsp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zu Beginn muss die Google-Drive eingerichtet werden, in der die Messdaten (OR0-Dateien) gespeichert sind. Danach werden alle verfügbaren Unterordner aufgerufen. So wird geprüft, ob der Mount richtig funktioniert hat."
      ],
      "metadata": {
        "id": "EKAQlrHyWWIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "# Durchsuche den Google Drive-Pfad\n",
        "for root, dirs, files in os.walk(drive_path):\n",
        "    for dir in dirs:\n",
        "        # Gib den Namen des Unterordners aus\n",
        "        print(os.path.join(root, dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_iN54-sVUVL",
        "outputId": "49006586-b536-46c3-c253-11318c9a0c34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab_Notebooks\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            "/content/drive/MyDrive/Colab_Notebooks/CSV_Messdaten\n",
            "/content/drive/MyDrive/Colab_Notebooks/CouchDB File\n",
            "/content/drive/MyDrive/Colab_Notebooks/NasaAmes_Messdaten\n",
            "/content/drive/MyDrive/Colab_Notebooks/NasaAmes_Messdaten/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Danach werden die einzelnen OR0-Dateien (NasaAmes Format) geladen und umgewandelt.\n",
        "\n",
        "Das NasaAmes Format: https://espoarchive.nasa.gov/content/Ames_Format_Specification_v20\n",
        "\n",
        "Die Messdaten sind unter dem FFI (File Format Index) 2005 gespeichert. Dieser Standard ist durch die Nasa nicht dokumentiert. Deshalb nachfolgend ein eigener Parser, der die Daten in eine nutzbare CSV umwandelt."
      ],
      "metadata": {
        "id": "ZRL9H_KEZpgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dict und Inhalt**\n",
        "\n",
        "- **file_names** = enthält die Dateinamen der einzelnen OR0-Dateien\n",
        "- **file_content** = Enthält den Inhalt der OR0-Dateien\n",
        "- **end_line_header** = enthält die Zeile an dem der Header endet"
      ],
      "metadata": {
        "id": "TI_gn6B6_qGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dateien einlesen:**"
      ],
      "metadata": {
        "id": "7_mIBaD2FwwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zum Ordner mit den Dateien in Google Drive\n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/NasaAmes_Messdaten/Data'\n",
        "\n",
        "# OR0-Dateien im Ordner lesen\n",
        "file_paths = glob.glob(folder_path + '/*.OR0')\n",
        "\n",
        "# Liste für die Dateinamen erstellen\n",
        "file_names = []\n",
        "\n",
        "# Schleife über die Dateien\n",
        "for file_path in file_paths:\n",
        "\n",
        "    if os.path.getsize(file_path) > 100 * 1024:\n",
        "      # Dateiname extrahieren\n",
        "      file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "      # Datei öffnen und Inhalt lesen\n",
        "      with open(file_path, 'r') as file:\n",
        "          file_content = file.read()\n",
        "\n",
        "      # Variable für die Datei erstellen\n",
        "      globals()[file_name] = file_content\n",
        "\n",
        "      file_names.append(file_name)"
      ],
      "metadata": {
        "id": "LJXRx3MKM8L1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(file_names)"
      ],
      "metadata": {
        "id": "79U8aYImoj-J",
        "outputId": "87016524-31d2-4463-8644-4c16a991ac21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SA220615', 'SA220616', 'SA220617', 'SA220618', 'SA220619', 'SA220620', 'SA220621', 'SA220622', 'SA220623', 'SA220624', 'SA220625', 'SA220626', 'SA220627', 'SA220628', 'SA220629', 'SA220630', 'SA220701', 'SA220702', 'SA220703', 'SA220704', 'SA220705', 'SA220707', 'SA220708', 'SA220709', 'SA220710', 'SA220711', 'SA220712', 'SA220713', 'SA220714', 'SA220715', 'SA220716', 'SA220717', 'SA220718', 'SA220719', 'SA220720', 'SA220721', 'SA220722', 'SA220723', 'SA220724', 'SA220725', 'SA220726', 'SA220727', 'SA220728', 'SA220729', 'SA220730', 'SA220731', 'SA220801', 'SA220802', 'SA220803', 'SA220804', 'SA220805', 'SA220806', 'SA220807', 'SA220808', 'SA220809', 'SA220810', 'SA220811', 'SA220812', 'SA220813', 'SA220814', 'SA220815', 'SA220816', 'SA220817', 'SA220818', 'SA220819', 'SA220820', 'SA220821', 'SA220822', 'SA220823', 'SA220824', 'SA220825', 'SA220826', 'SA220827', 'SA220829', 'SA220830', 'SA220831', 'SA220901', 'SA220902', 'SA220906', 'SA220907', 'SA220908', 'SA220909', 'SA220912', 'SA220913', 'SA220914', 'SA220915', 'SA220916', 'SA220917', 'SA220918', 'SA220919', 'SA220920', 'SA220921', 'SA220922', 'SA220923', 'SA220924', 'SA220926', 'SA220927', 'SA220928', 'SA220929', 'SA220930', 'SA221001', 'SA221002', 'SA221003', 'SA221004', 'SA221005', 'SA221006', 'SA221007', 'SA221008', 'SA221009', 'SA221010', 'SA221011', 'SA221012', 'SA221013', 'SA221014', 'SA221015', 'SA221016', 'SA221017', 'SA221018', 'SA221019', 'SA221020', 'SA221021', 'SA221022', 'SA221023', 'SA221024', 'SA221025', 'SA221026', 'SA221027', 'SA221028', 'SA221029', 'SA221030', 'SA221031', 'SA221101', 'SA221102', 'SA221103', 'SA221104', 'SA221105', 'SA221106', 'SA221107', 'SA221108', 'SA221109', 'SA221110', 'SA221111', 'SA221112', 'SA221113', 'SA221114', 'SA221115', 'SA221116', 'SA221117', 'SA221118', 'SA221119', 'SA221121', 'SA221122', 'SA221123', 'SA221124', 'SA221125', 'SA221126', 'SA221127', 'SA221128', 'SA221129', 'SA221130', 'SA221201', 'SA221202', 'SA221203', 'SA221204', 'SA221205', 'SA221206', 'SA221207', 'SA221208', 'SA221209', 'SA221210', 'SA221211', 'SA221212', 'SA221213', 'SA221214', 'SA221215', 'SA221216', 'SA221217', 'SA221219', 'SA221220', 'SA221221', 'SA221222', 'SA221223', 'SA221224', 'SA230103', 'SA230104', 'SA230105', 'SA230106', 'SA230107', 'SA230108', 'SA230109', 'SA230110', 'SA230111', 'SA230112', 'SA230113', 'SA230114', 'SA230115', 'SA230116', 'SA230117', 'SA230118', 'SA230119', 'SA230120', 'SA230121', 'SA230122', 'SA230123', 'SA230124', 'SA230125', 'SA230126', 'SA230127', 'SA230128', 'SA230129', 'SA230130', 'SA230131', 'SA230201', 'SA230202', 'SA230203', 'SA230204', 'SA230205', 'SA230206', 'SA230207', 'SA230208', 'SA230209', 'SA230210', 'SA230211', 'SA230212', 'SA230213', 'SA230214', 'SA230215', 'SA230216', 'SA230217', 'SA230218', 'SA230219', 'SA230220', 'SA230221', 'SA230222', 'SA230223', 'SA230224', 'SA230225', 'SA230226', 'SA230227', 'SA230228', 'SA230301', 'SA230302', 'SA230303', 'SA230304', 'SA230305', 'SA230306', 'SA230307', 'SA230308', 'SA230309', 'SA230310', 'SA230311', 'SA230312', 'SA230313', 'SA230314', 'SA230315', 'SA230316', 'SA230317', 'SA230318', 'SA230319', 'SA230320', 'SA230321', 'SA230322', 'SA230323', 'SA230324', 'SA230325', 'SA230328', 'SA230329', 'SA230330', 'SA230331', 'SA230401', 'SA230402', 'SA230403', 'SA230404', 'SA230405', 'SA230406', 'SA230407', 'SA230408', 'SA230409', 'SA230410', 'SA230411', 'SA230412', 'SA230413', 'SA230414', 'SA230417', 'SA230418', 'SA230419', 'SA230420', 'SA230421', 'SA230422', 'SA230423', 'SA230424', 'SA230425', 'SA230426', 'SA230427', 'SA230428', 'SA230429', 'SA230430', 'SA230501', 'SA230502', 'SA230503', 'SA230504', 'SA230505', 'SA230506', 'SA230507', 'SA230508', 'SA230509', 'SA230510', 'SA230511', 'SA230512', 'SA230513', 'SA230514', 'SA230515', 'SA230516', 'SA230517', 'SA230519', 'SA230520', 'SA230521', 'SA230522', 'SA230523', 'SA230524', 'SA230525', 'SA230526']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**String aufteilen in einzelne Zeile schreiben:**"
      ],
      "metadata": {
        "id": "P4FUkD2Lua3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_variables = {}  # Dictionary für die Variablen erstellen\n",
        "\n",
        "for file_name in file_names:\n",
        "    file_content = globals()[file_name]\n",
        "    file_variables[file_name] = file_content\n",
        "\n",
        "# Auf Variablen zugreifen und String in Zeilen aufteilen\n",
        "for file_name, variable in file_variables.items():\n",
        "    file_variables[file_name] = file_variables[file_name].split('\\n')"
      ],
      "metadata": {
        "id": "JxBOhrPFQIYc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# die ersten 10 File Namen ausgeben und die ersten 20 Zeilen der ersten Datei\n",
        "# print(file_names[:10])\n",
        "# file_variables['SA220615'][:20]"
      ],
      "metadata": {
        "id": "39IUSb11vuGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Header extrahieren:**"
      ],
      "metadata": {
        "id": "AaUuqtlgK2Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funktion um den Dateiheader zu extrahieren\n",
        "def extract_header(dataset):\n",
        "    header_content = \"\"\n",
        "    end_line_header = None\n",
        "\n",
        "    for i, line in enumerate(dataset):\n",
        "        header_content += line + \"\\n\"\n",
        "        if line.strip() == \"Pyranometer: readout interval [secs]=5\":\n",
        "            end_line_header = i\n",
        "            break\n",
        "\n",
        "\n",
        "    return header_content, end_line_header"
      ],
      "metadata": {
        "id": "YQTw-OjYPUkp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict = {file_name: None for file_name in file_names}"
      ],
      "metadata": {
        "id": "HJpasS1MMspW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_action(file_variables, file_names):\n",
        "    header_dict = {file_name: \"\" for file_name in file_names}\n",
        "\n",
        "    for file_name, data in file_variables.items():\n",
        "        for i, line in enumerate(data):\n",
        "            header_dict[file_name] += line + \"\\n\"\n",
        "            if line.strip() == \"Pyranometer: readout interval [secs]=5\":\n",
        "                end_line_header_fnc = i\n",
        "                break\n",
        "\n",
        "    return header_dict, end_line_header_fnc"
      ],
      "metadata": {
        "id": "rBjd_Y6lEw80"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_header, end_line_header = perform_action(file_variables, file_names)"
      ],
      "metadata": {
        "id": "nUdv6oMbE2-q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe mit Wellenlängen erstellen:**"
      ],
      "metadata": {
        "id": "4sWE034DaFBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df_Wellenlaenge(start, end, step):\n",
        "    # Erstelle eine Liste mit den gewünschten Werten\n",
        "    numbers_list = [round(num, 3) for num in list(np.arange(start, end + step, step))]\n",
        "    # Erstelle den Dataframe\n",
        "    df = pd.DataFrame({'Wellenlaenge': numbers_list})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "vR4lB-9hAJZ6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_Wellenlaenge = np.round(np.arange(290.0, 420.05, 0.1), decimals = 1)\n",
        "df_Wellenlaenge = pd.DataFrame({'Wellenlaenge': np_Wellenlaenge})"
      ],
      "metadata": {
        "id": "ke6b38SlA3B1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nach Datum in Header suchen:**"
      ],
      "metadata": {
        "id": "OTl6cJnMLlVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_dates_from_dict(dictionary):\n",
        "    dates = {}\n",
        "\n",
        "    for key, value in dictionary.items():\n",
        "        header_content = value  # Annahme: Der Wert im Dictionary enthält den Header-Inhalt\n",
        "        header_split = header_content.split('\\n')\n",
        "        date_line = header_split[6].split()\n",
        "        start_date = \"-\".join(date_line[:3])\n",
        "        end_date = \"-\".join(date_line[3:])\n",
        "\n",
        "        if start_date == end_date:\n",
        "            date_object = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "            dates[key] = date_object\n",
        "        else:\n",
        "            dates[key] = \"Error: Start and end dates are not the same\"\n",
        "            print(\"Error: Start and end dates are not the same\")\n",
        "\n",
        "    return dates"
      ],
      "metadata": {
        "id": "yMbKmP07It7V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date = extract_dates_from_dict(file_header)"
      ],
      "metadata": {
        "id": "MZ-113EHGHDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Header aus Datensatz löschen:**"
      ],
      "metadata": {
        "id": "L_0hAYmkOyxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_header(lines_content, end_line):\n",
        "    lines_WO_header_fnc = {}\n",
        "    lines_WO_header_fnc = lines_content.copy()\n",
        "\n",
        "    for key, value in lines_WO_header_fnc.items():\n",
        "        del value[:end_line+1]\n",
        "\n",
        "    return lines_WO_header_fnc"
      ],
      "metadata": {
        "id": "a9HPMKEdffX1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_WO_header = remove_header(file_variables, end_line_header)"
      ],
      "metadata": {
        "id": "hxWLzYdkff7w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines_WO_header['SA220615'][:20])"
      ],
      "metadata": {
        "id": "fOR-FkULhDAQ",
        "outputId": "f72c2fe4-0a6d-4f34-b073-623a0999e1e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['26460', '113 4.000E-02 9.999E+9', '2.000E+00 0.000E+00 999.9 9.999E+9 9.999E+9 ', '9.999E+9 9.999E+9 9.999E+9 9.999E+9', '9.999E+9 9.999E+9 9.999E+9 9.999E+9', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00', '  0.0000E+00  2.3451E-05  9.6566E-05  1.0385E-04  9.8287E-05']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datensatz als CSV speichern:**"
      ],
      "metadata": {
        "id": "ssEk9zfbS8uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_to_csv(dict_data, file_path):\n",
        "    with open(file_path, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(dict_data.keys())\n",
        "        writer.writerow(dict_data.values())"
      ],
      "metadata": {
        "id": "doq_ij2fYP2S",
        "outputId": "c2560394-1d61-4932-ba1f-2a1f1999f687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-74bdff7e6aad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_WO_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path ="
      ],
      "metadata": {
        "id": "yFFOClvsYUe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_to_csv(lines_WO_header, file_path)"
      ],
      "metadata": {
        "id": "Ll-XK7gYZBQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeitstempel in Datensatz finden:**"
      ],
      "metadata": {
        "id": "uscoR4cRFvIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funktion um den Anfang einer einzelnen Messung zu finden\n",
        "def split_dataset(dataset):\n",
        "    data_packages = []\n",
        "    current_package = []\n",
        "\n",
        "    for i, line in enumerate(dataset):\n",
        "        if line.strip().isdigit() and len(line.strip()) == 5:\n",
        "            if i + 1 < len(dataset) and dataset[i + 1].strip().isdigit() and len(dataset[i + 1].strip()) in [2, 3]:\n",
        "                if current_package:\n",
        "                    data_packages.append(current_package)\n",
        "                    current_package = []\n",
        "            current_package.append(line)\n",
        "\n",
        "    if current_package:\n",
        "        data_packages.append(current_package)\n",
        "\n",
        "    return data_packages"
      ],
      "metadata": {
        "id": "WI-aukhcgE1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_packages = split_dataset(lines_WO_header)"
      ],
      "metadata": {
        "id": "3dJYofTuiM6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_packages"
      ],
      "metadata": {
        "id": "jLWq_ImUR3l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Den Zeitstempeln ein Indice zuorden:"
      ],
      "metadata": {
        "id": "zyN8Idu93o1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_indices(elemente, meine_liste):\n",
        "    indices = []\n",
        "\n",
        "    for element in elemente:\n",
        "        if element in meine_liste:\n",
        "            indices.append(meine_liste.index(element))\n",
        "        else:\n",
        "            indices.append(-1)\n",
        "\n",
        "    return indices"
      ],
      "metadata": {
        "id": "ud464ZrF3pL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispielaufruf der Funktion\n",
        "indices_Timestamp = find_indices(package, lines_WOH_split)\n",
        "print(indices_Timestamp)"
      ],
      "metadata": {
        "id": "NwmqQb2U32ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeitstempel in eine Uhrzeit umwandeln:**"
      ],
      "metadata": {
        "id": "Qh26OqFdZOgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funktion um den Zeitstempel der Messung in eine Uhrzeit und ein Datum umzuwandeln\n",
        "def seconds_to_time(time_seconds, date):\n",
        "    data = []\n",
        "\n",
        "    for sec in time_seconds:\n",
        "        hours = int(sec) // 3600\n",
        "        minutes = (int(sec) % 3600) // 60\n",
        "        seconds = int(sec) % 60\n",
        "        time = pd.to_datetime(f\"{date} {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
        "        data.append({'Datum':date,'Stunden': hours, 'Minuten': minutes, 'Sekunden': seconds, 'Uhrzeit': time})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "vOmsONI3iaNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_time = seconds_to_time(package, date)\n",
        "\n",
        "# Ausgabe des DataFrames\n",
        "print(df_time)"
      ],
      "metadata": {
        "id": "DbmsPJVw7Rcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Herausschreiben der einzelnen Messungen**"
      ],
      "metadata": {
        "id": "5hJxnPp03cSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spalten des Datensatz in einzelne Elemente aufteilen:"
      ],
      "metadata": {
        "id": "FBHCpg_g5GPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_list = extract_numbers(lines_WO_header)"
      ],
      "metadata": {
        "id": "_K6jgcAeO57S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_columns(df):\n",
        "    new_columns = {}\n",
        "    for column in df.columns:\n",
        "        split_values = df[column].str.split(' ', expand=True)\n",
        "        num_values = split_values.shape[1]\n",
        "        new_columns.update({f'{column}_{i+1}': split_values[i] for i in range(num_values)})\n",
        "\n",
        "    df_split = pd.DataFrame(new_columns)\n",
        "    return df_split"
      ],
      "metadata": {
        "id": "zDSg5wEC84aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def split_data(lines_WOH_fnc, split_indices):\n",
        "    data_parts = []\n",
        "    for i in range(len(split_indices)):\n",
        "        if i == 0:\n",
        "            data_parts.append(lines_WOH_fnc[:split_indices[i]])\n",
        "        else:\n",
        "            data_parts.append(lines_WOH_fnc[split_indices[i-1]:split_indices[i]])\n",
        "    data_parts.append(lines_WOH_fnc[split_indices[-1]:])\n",
        "    df = pd.DataFrame(data_parts)\n",
        "    num_cols = max([len(x) for x in data_parts])\n",
        "    col_names = ['Col{}'.format(i+1) for i in range(num_cols)]\n",
        "    df.columns = col_names\n",
        "    df = df.drop(df.index[0]).reset_index(drop=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "1IEkUxzb3i-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines_WO_header[:5], type(data_packages[0]))"
      ],
      "metadata": {
        "id": "DWzXzxAC6J_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Messung = split_data(lines_WOH_split, indices_Timestamp)\n",
        "print(df_Messung)"
      ],
      "metadata": {
        "id": "ry_pkWk-3-GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe in die richtige Form bringen:"
      ],
      "metadata": {
        "id": "V1Ix8IzK-7Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Mea_Time = pd.concat([df_time, df_Messung], axis = 1)"
      ],
      "metadata": {
        "id": "3b5raYOF-2QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_index = 18\n",
        "num_elements = 1301\n",
        "\n",
        "columns_to_rename = [\"Col\" + str(i) for i in range(start_index, start_index + num_elements)]"
      ],
      "metadata": {
        "id": "wyS4DeYMGCWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in columns_to_rename:\n",
        "    old_column_name = item\n",
        "    new_column_name = str(df_Wellenlaenge.loc[columns_to_rename.index(item), 'Wellenlaenge'])\n",
        "    df_Mea_Time.rename(columns={old_column_name: new_column_name}, inplace=True)"
      ],
      "metadata": {
        "id": "8Coe44KnkCIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Mea_Time"
      ],
      "metadata": {
        "id": "Ajb2jGIaa8De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abspeichern der Messdaten als CSV**"
      ],
      "metadata": {
        "id": "g7Cbzs6Yy2DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Mea_Time.to_csv('/content/drive/MyDrive/Colab_Notebooks/CSV_Messdaten/mea_time.csv', index=False)"
      ],
      "metadata": {
        "id": "nrQIIzsSlO7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}