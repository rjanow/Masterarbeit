{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuVBuRrFsvq4hOPLFCbTO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/Modeling_and_Prediction_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM BASELINE MODEL"
      ],
      "metadata": {
        "id": "0Ng7WlqRF6Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Skript wird ein erstes Modell erzeugt, um aus den gemssenen Globalstrahlungsdaten den UVI zu berechen."
      ],
      "metadata": {
        "id": "AsUt2K5PFuQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbinden mit der Google-Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN5x7YhZ99QP",
        "outputId": "4d1b7edb-5c0d-43da-aa74-9d014284e5a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XgnNp1CjFzPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSK4Ns8Op4YG",
        "outputId": "41d68f58-09cd-4b1f-87e5-499594384acb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "L1rcvDzU-F-w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funktionen:"
      ],
      "metadata": {
        "id": "KwH3fCP0Y-F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sMAPE Funktion zum brechnen des symmetric mean absolute percentage error\n",
        "def smape(y_true, y_pred):\n",
        "    diff = K.abs(y_true - y_pred)\n",
        "    denom = K.abs(y_true) + K.abs(y_pred)\n",
        "    return 200.0 * K.mean(diff / (denom + K.epsilon()))"
      ],
      "metadata": {
        "id": "VfGh4u0ULVkV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "o4-tDR37Y9dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zur CSV-Datei auf Google-Drive\n",
        "name_Messwerte = 'Messdaten_CAMS_GHI.csv'\n",
        "name_Vorhersage = 'Vorhersagedaten_CAMS_VarIdx.csv'\n",
        "folder_import = '/content/drive/My Drive/Colab_Notebooks/Clean_Data/'"
      ],
      "metadata": {
        "id": "yBFyA7hw9-XT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zum Abspeichern des trainierten Modells in Google-Drive\n",
        "\n",
        "model_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/full_model.keras'\n",
        "weights_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_weights.weights.h5'\n",
        "\n",
        "# Pfad für den Testdatensatz\n",
        "\n",
        "testdata_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_testdata.csv'"
      ],
      "metadata": {
        "id": "d0Cj9p-p5yu2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Messdaten\n",
        "df_Messdaten = pd.read_csv(folder_import + name_Messwerte)"
      ],
      "metadata": {
        "id": "1RAsBy3qGHTE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Vorhersagedaten\n",
        "df_Vorhersage = pd.read_csv(folder_import + name_Vorhersage)"
      ],
      "metadata": {
        "id": "t1qhUxgIUU3v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konvertiere die Zeitspalten in ein gemeinsames Format und führe einen Merge der Datensätze durch\n",
        "df_Messdaten['Datetime'] = pd.to_datetime(df_Messdaten['Datetime'])\n",
        "df_Vorhersage['Datetime'] = pd.to_datetime(df_Vorhersage['Datetime'])"
      ],
      "metadata": {
        "id": "ETDBeb_894PE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spalten in den Messdaten\n",
        "df_Messdaten.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCdeBkhdUqUJ",
        "outputId": "840c4799-3700-49bf-d223-a2662ad28b25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Datetime', 'Observation_period', 'Clear_sky_GHI', 'Clear_sky_BHI',\n",
              "       'GHI', 'BHI', 'UVI', 'UVA', 'UVB', 'erythem', 'Datum', 'Uhrzeit',\n",
              "       'Messzeitpunkt', 'ghi', 'Dif', 'Glo_SPLite', 'Dir', 'Temp',\n",
              "       'DiffGreater2', 'SZA', 'time_sin', 'time_cos', 'date_sin', 'date_cos',\n",
              "       'Date', 'Hour'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "xju0lfd5awtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"units_1\": 64,\n",
        "    \"units_2\": 32,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"final_activation\": \"linear\"\n",
        "}"
      ],
      "metadata": {
        "id": "rAe1lsV6Y7EB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_config = {\n",
        "    \"loss\": \"mean_squared_error\",\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"metrics\": [\n",
        "        \"mse\",\n",
        "        \"mae\",\n",
        "        \"mape\",\n",
        "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "hhLV4E0Va0O_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "Q3cZJrysZFmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispiel: Nur 'SZA' als Feature und 'UVI' als Label\n",
        "columns_X = ['ghi']\n",
        "columns_y = ['UVI']\n",
        "\n",
        "df = df_Messdaten.copy()  # deine Messdaten\n",
        "\n",
        "total_length = len(df)\n",
        "train_size   = round(total_length * 0.80)\n",
        "val_size     = round(total_length * 0.10)\n",
        "test_size    = total_length - train_size - val_size  # restliche 10%\n",
        "\n",
        "# Skaliere X und Y separat (immer zuerst nur auf dem Trainingsbereich fitten!)\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# 1) Nur Trainingsdatensatz extrahieren\n",
        "train_df = df.iloc[:train_size]\n",
        "# Fit des Scalers NUR auf Trainingsdaten\n",
        "train_df[columns_X] = scaler_X.fit_transform(train_df[columns_X])\n",
        "train_df[columns_y] = scaler_y.fit_transform(train_df[columns_y])\n",
        "\n",
        "# 2) Für Validation\n",
        "val_df = df.iloc[train_size : train_size + val_size].copy()\n",
        "val_df[columns_X] = scaler_X.transform(val_df[columns_X])\n",
        "val_df[columns_y] = scaler_y.transform(val_df[columns_y])\n",
        "\n",
        "# 3) Für Test\n",
        "test_df = df.iloc[train_size + val_size :].copy()\n",
        "test_df[columns_X] = scaler_X.transform(test_df[columns_X])\n",
        "test_df[columns_y] = scaler_y.transform(test_df[columns_y])\n",
        "\n",
        "# Kontrolle\n",
        "print(\"Train:\", train_df.shape)\n",
        "print(\"Val:\", val_df.shape)\n",
        "print(\"Test:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArmMIX9h0zAO",
        "outputId": "402b755a-e3fc-4ff2-ce57-a280a66deaae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (77386, 26)\n",
            "Val: (9673, 26)\n",
            "Test: (9673, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-f8bf0a26c930>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df[columns_X] = scaler_X.fit_transform(train_df[columns_X])\n",
            "<ipython-input-13-f8bf0a26c930>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df[columns_y] = scaler_y.fit_transform(train_df[columns_y])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence(X, y, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for stop_idx in range(seq_length, len(X)):\n",
        "        x_seq = X.iloc[stop_idx-seq_length:stop_idx].values  # (seq_length, num_features)\n",
        "        y_label = y.iloc[stop_idx]                           # Wert am Zeitpunkt 'stop_idx'\n",
        "        sequences.append(x_seq)\n",
        "        labels.append(y_label)\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "Bgzb01Gy01MY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_OneStepAhead(X, y, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    # bis len(X)-1, damit \"stop_idx + 1\" nicht out-of-range ist\n",
        "    for stop_idx in range(seq_length, len(X)-1):\n",
        "        x_seq = X.iloc[stop_idx-seq_length:stop_idx].values\n",
        "        y_label = y.iloc[stop_idx + 1]  # => label ist der nächste Zeitschritt\n",
        "        sequences.append(x_seq)\n",
        "        labels.append(y_label)\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "1BCYvGNv03yO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = 16\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequence(train_df[columns_X], train_df[columns_y], sequence_len)\n",
        "X_val_seq,   y_val_seq   = create_sequence(val_df[columns_X],   val_df[columns_y],   sequence_len)\n",
        "X_test_seq,  y_test_seq  = create_sequence(test_df[columns_X],  test_df[columns_y],  sequence_len)\n",
        "\n",
        "print(X_train_seq.shape, y_train_seq.shape)\n",
        "print(X_val_seq.shape,   y_val_seq.shape)\n",
        "print(X_test_seq.shape,  y_test_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uSG1jbc0-28",
        "outputId": "b47cb91a-f3d7-4daa-de46-260a5cd2e8e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77370, 16, 1) (77370, 1)\n",
            "(9657, 16, 1) (9657, 1)\n",
            "(9657, 16, 1) (9657, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (16, 1)"
      ],
      "metadata": {
        "id": "SxZJ0UsZ1BYX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_compile_model(model_config, training_config, input_shape):\n",
        "    \"\"\"\n",
        "    Baut ein Keras Sequential Model anhand der übergebenen Konfigurationen\n",
        "    und kompiliert es mit den Trainingseinstellungen.\n",
        "\n",
        "    Parameter:\n",
        "    -----------\n",
        "    model_config: dict\n",
        "        Dict mit Keys wie 'units_1', 'units_2', 'dropout_rate', 'final_activation'\n",
        "    training_config: dict\n",
        "        Dict mit Keys wie 'loss', 'optimizer', 'metrics'\n",
        "    input_shape: tuple\n",
        "        Form deiner Eingabedaten, z.B. (timesteps, features)\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    model : keras.Model\n",
        "        Das fertig kompilierte Modell.\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=model_config[\"units_1\"],\n",
        "            return_sequences=True,\n",
        "            input_shape=input_shape\n",
        "        )\n",
        "    )\n",
        "    model.add(Dropout(model_config[\"dropout_rate\"]))\n",
        "\n",
        "    # Zweite LSTM-Schicht\n",
        "    model.add(LSTM(units=model_config[\"units_2\"]))\n",
        "\n",
        "    # Dense-Ausgangsschicht\n",
        "    model.add(Dense(1, activation=model_config[\"final_activation\"]))\n",
        "\n",
        "    # Kompilieren\n",
        "    model.compile(**training_config)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "TWB7UCHP1Dak"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])  # z.B. (16, 1)\n",
        "\n",
        "model = build_and_compile_model(\n",
        "    model_config=model_config,\n",
        "    training_config=training_config,\n",
        "    input_shape=input_shape\n",
        ")"
      ],
      "metadata": {
        "id": "x6MQPmZ2bTQM",
        "outputId": "0cf47a02-1a7c-4c1f-ed2c-4e5f12704a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    validation_data=(X_val_seq, y_val_seq),\n",
        "    epochs=5, batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln2ZkEBrkxY6",
        "outputId": "2f463302-311e-4b57-8cb9-3dff1b5ae0a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2418/2418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0437 - mape: 5255.3145 - mse: 0.0056 - rmse: 0.0730 - val_loss: 0.0072 - val_mae: 0.0566 - val_mape: 41.9400 - val_mse: 0.0072 - val_rmse: 0.0848\n",
            "Epoch 2/5\n",
            "\u001b[1m2418/2418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 21ms/step - loss: 0.0034 - mae: 0.0355 - mape: 3358.4612 - mse: 0.0034 - rmse: 0.0581 - val_loss: 0.0078 - val_mae: 0.0606 - val_mape: 55.7025 - val_mse: 0.0078 - val_rmse: 0.0882\n",
            "Epoch 3/5\n",
            "\u001b[1m2418/2418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 21ms/step - loss: 0.0031 - mae: 0.0339 - mape: 2806.1763 - mse: 0.0031 - rmse: 0.0555 - val_loss: 0.0072 - val_mae: 0.0574 - val_mape: 46.5257 - val_mse: 0.0072 - val_rmse: 0.0850\n",
            "Epoch 4/5\n",
            "\u001b[1m2418/2418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 21ms/step - loss: 0.0030 - mae: 0.0329 - mape: 2162.2866 - mse: 0.0030 - rmse: 0.0544 - val_loss: 0.0079 - val_mae: 0.0600 - val_mape: 57.0696 - val_mse: 0.0079 - val_rmse: 0.0888\n",
            "Epoch 5/5\n",
            "\u001b[1m2418/2418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 20ms/step - loss: 0.0029 - mae: 0.0322 - mape: 2741.5144 - mse: 0.0029 - rmse: 0.0534 - val_loss: 0.0072 - val_mae: 0.0578 - val_mape: 56.5631 - val_mse: 0.0072 - val_rmse: 0.0848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Evaluieren (Keras-integrierte Metriken)\n",
        "val_results = model.evaluate(X_val_seq, y_val_seq, verbose=0)\n",
        "test_results = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
        "print(\"Model metrics names:\", model.metrics_names)\n",
        "\n",
        "# 3) Vorhersagen für weitere Kennzahlen (z.B. R2-Score)\n",
        "y_val_pred = model.predict(X_val_seq).flatten()\n",
        "y_test_pred = model.predict(X_test_seq).flatten()\n",
        "\n",
        "val_r2  = r2_score(y_val_seq, y_val_pred)\n",
        "test_r2 = r2_score(y_test_seq, y_test_pred)\n",
        "\n",
        "# 4) Dictionary bauen\n",
        "metrics = {\n",
        "    \"val_loss\": val_results[0],\n",
        "    \"val_mse\":  val_results[1],\n",
        "    \"val_mae\":  val_results[2],\n",
        "    \"val_rmse\": val_results[3],\n",
        "    \"test_loss\": test_results[0],\n",
        "    \"test_mse\":  test_results[1],\n",
        "    \"test_mae\":  test_results[2],\n",
        "    \"test_rmse\": test_results[3],\n",
        "    \"val_r2\": val_r2,\n",
        "    \"test_r2\": test_r2\n",
        "}"
      ],
      "metadata": {
        "id": "Ys86VBr57sQE",
        "outputId": "0a5affe2-5c52-49a7-d1f7-6a33db14f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model metrics names: ['loss', 'compile_metrics']\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'r2_score' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-57897597feb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mval_r2\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechnen des vorhergesagten UVI\n",
        "y_pred = model.predict(X_test_seq)"
      ],
      "metadata": {
        "id": "4bxULDGoGp92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.flatten()\n",
        "y_test_seq = y_test_seq.flatten()"
      ],
      "metadata": {
        "id": "TjK_j366Dvc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_pred)"
      ],
      "metadata": {
        "id": "x5LAKe82EFa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Püfen, ob die Vorhersage den selben Shape hat wie\n",
        "print(y_pred.shape, y_test_seq.shape)"
      ],
      "metadata": {
        "id": "x5qP8JayLkjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abspeichern des trainierten Modells und der Gewichte\n",
        "\n",
        "model.save(model_path)\n",
        "model.save_weights(weights_path)\n",
        "\n",
        "# Abspeichern des Testdatensatzes für eine spätere Auswertung"
      ],
      "metadata": {
        "id": "6X_QA6DJ5rXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Berechnung der Qualitätsparameter:"
      ],
      "metadata": {
        "id": "GKskVQkk7Wiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_model_output(model, X_test, y_test, plot_indices=None):\n",
        "    \"\"\"\n",
        "    Vergleicht den Output des Modells mit den wahren Testdaten.\n",
        "\n",
        "    Parameter:\n",
        "    -----------\n",
        "    model : keras.Model\n",
        "        Das trainierte Modell.\n",
        "    X_test : np.array\n",
        "        Die Eingabedaten (Sequenzen) für den Test.\n",
        "    y_test : np.array\n",
        "        Die tatsächlichen Zielwerte (Labels) für den Test.\n",
        "    plot_indices : tuple or list (optional)\n",
        "        Falls angegeben, z.B. (start, end), wird nur dieser Abschnitt für einen Detailplot verwendet.\n",
        "    \"\"\"\n",
        "\n",
        "    # Vorhersage berechnen\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Arrays abflachen für leichtere Handhabung\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_test = y_test.flatten()\n",
        "\n",
        "    # Metriken berechnen\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    # Ergebnis ausgeben\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "    # Gesamten Vergleich plotten\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(y_pred, label='Vorhersage', alpha=0.7)\n",
        "    plt.plot(y_test, label='Tatsächlicher Wert', alpha=0.7)\n",
        "    plt.title('Vergleich Vorhersage vs. Tatsächlicher Wert')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Optionaler Detailplot für einen Index-Bereich\n",
        "    if plot_indices is not None:\n",
        "        start, end = plot_indices\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.plot(np.arange(start, end), y_pred[start:end], label='UVI Vorhersage', alpha=0.7)\n",
        "        plt.plot(np.arange(start, end), y_test[start:end], label='UVI Messung', alpha=0.7)\n",
        "        plt.title(f'Detailplot (Index {start} - {end})')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "C3AP07dK-b1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_model_output(model, X_test_seq, y_test_seq, plot_indices=None)"
      ],
      "metadata": {
        "id": "ZL4b3_wP-v0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_model_output(model, X_test_seq[:750], y_test_seq[:750], plot_indices=None)"
      ],
      "metadata": {
        "id": "w_bEh_WSFAGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_largest_deviation(y_pred, y_true, window=250):\n",
        "    \"\"\"\n",
        "    Findet die größte Abweichung zwischen Vorhersage und Messwerten und plottet\n",
        "    den Bereich von [i-window, i+window] um diesen Index herum.\n",
        "\n",
        "    Parameter:\n",
        "    -----------\n",
        "    y_pred : np.array\n",
        "        Array der Vorhersagewerte (z.B. Modelloutput).\n",
        "    y_true : np.array\n",
        "        Array der gemessenen True-Werte (Labels).\n",
        "    window : int, optional (default=250)\n",
        "        Anzahl an Werten vor und nach dem Index der größten Abweichung,\n",
        "        die im Detailplot dargestellt werden sollen.\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    None (erstellt ein Plot).\n",
        "    \"\"\"\n",
        "\n",
        "    # Sicherstellen, dass beide Arrays gleich lang sind\n",
        "    if len(y_pred) != len(y_true):\n",
        "        raise ValueError(f\"Inkonsistente Längen: y_pred={len(y_pred)}, y_true={len(y_true)}\")\n",
        "\n",
        "    # Index der größten Abweichung bestimmen\n",
        "    diff = np.abs(y_pred - y_true)\n",
        "    max_idx = np.argmax(diff)\n",
        "\n",
        "    # Anzeigebereich für den Plot definieren (Begrenzung beachten)\n",
        "    start_idx = max(0, max_idx - window)\n",
        "    end_idx = min(len(y_pred), max_idx + window)\n",
        "\n",
        "    # Plot erstellen\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(np.arange(start_idx, end_idx), y_true[start_idx:end_idx],\n",
        "             label='Messwerte (y_val)', alpha=0.7)\n",
        "    plt.plot(np.arange(start_idx, end_idx), y_pred[start_idx:end_idx],\n",
        "             label='Vorhersage (y_pred)', alpha=0.7)\n",
        "    # Hervorhebung des Punktes mit größter Abweichung\n",
        "    plt.scatter(max_idx, y_true[max_idx], color='red', s=80, marker='x', label='Größte Abweichung')\n",
        "\n",
        "    plt.title(f'Größte Abweichung bei Index={max_idx} (Abweichung={diff[max_idx]:.4f})')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Wert')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RGu6mTeWFE_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_largest_deviation(y_pred, y_test_seq)"
      ],
      "metadata": {
        "id": "g_AEz_kjGIv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred, y_test_seq)"
      ],
      "metadata": {
        "id": "gGH6i8jQ4zpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_model_results_to_csv(model_name, config, metrics, csv_path=\"model_results.csv\"):\n",
        "    \"\"\"\n",
        "    Speichert Modellkonfiguration und Metriken in einer CSV\n",
        "    und gibt sie gleichzeitig auf der Konsole aus.\n",
        "\n",
        "    Parameter:\n",
        "    -----------\n",
        "    model_name : str\n",
        "        Bezeichner des Modells (z.B. 'Baseline LSTM' oder 'Experiment_1').\n",
        "    config : dict\n",
        "        Dictionary mit allen Hyperparametern/Einstellungen.\n",
        "        Beispiel: {'epochs': 5, 'batch_size': 32, 'units_1': 64}\n",
        "    metrics : dict\n",
        "        Dictionary mit den erzielten Metriken (Loss, MAE, RMSE usw.).\n",
        "        Beispiel: {'val_loss': 0.012, 'val_mae': 0.089, 'test_loss': 0.015}\n",
        "    csv_path : str\n",
        "        Pfad zur CSV-Datei, in die die Ergebnisse geloggt werden.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Zusammenführen aller Informationen in ein Dictionary\n",
        "    #    ('model_name' ist immer hilfreich zur Unterscheidung)\n",
        "    results_dict = {'model_name': model_name}\n",
        "    results_dict.update(config)\n",
        "    results_dict.update(metrics)\n",
        "\n",
        "    # 2) Anzeige in der Konsole (kannst du ggf. anpassen)\n",
        "    print(\"=== Model Results ===\")\n",
        "    for key, value in results_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(\"======================\\n\")\n",
        "\n",
        "    # 3) In einen DataFrame umwandeln (eine Zeile pro Modell)\n",
        "    df_results = pd.DataFrame([results_dict])\n",
        "\n",
        "    # 4) Schreiben oder Anhängen in die CSV\n",
        "    #    - Falls die Datei noch nicht existiert, Kopfzeile mitschreiben\n",
        "    #    - Falls doch, nur anhängen (header=False)\n",
        "    if not os.path.exists(csv_path):\n",
        "        df_results.to_csv(csv_path, index=False)\n",
        "    else:\n",
        "        df_results.to_csv(csv_path, mode='a', index=False, header=False)"
      ],
      "metadata": {
        "id": "X_W2T60755eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])"
      ],
      "metadata": {
        "id": "RJep2McgXp1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model_results_to_csv(\n",
        "    model_name=\"Baseline LSTM\",\n",
        "    model_config=model_config,\n",
        "    training_config=training_config,\n",
        "    metrics=metrics,\n",
        "    csv_path=\"model_results.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "HNul4aLxXs4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}