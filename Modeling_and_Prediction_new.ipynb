{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlvZHOdNKX58IkCSqGygz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/Modeling_and_Prediction_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB6UmPFWkff5"
      },
      "outputs": [],
      "source": [
        "!pip -q install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "6DMMu_9zpRMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproduzierbarkeit\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "733upzW0pRPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_Messwerte   = 'Messdaten_CAMS_GHI.csv'\n",
        "name_Vorhersage  = 'Vorhersagedaten_CAMS_VarIdx.csv'\n",
        "folder_import    = '/content/drive/My Drive/Colab_Notebooks/Clean_Data/'\n",
        "\n",
        "model_path       = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/full_model.keras'\n",
        "weights_path     = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_weights.weights.h5'\n",
        "\n",
        "testdata_path_X  = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_testdata_X.csv'\n",
        "testdata_path_Y  = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_testdata_Y.csv'\n",
        "\n",
        "text_file_path   = \"/content/drive/MyDrive/Colab_Notebooks/LSTM_Model/model_results.txt\"\n",
        "\n",
        "# Optional: Scaler speichern\n",
        "scaler_x_path    = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/scaler_X.pkl'\n",
        "scaler_y_path    = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/scaler_y.pkl'"
      ],
      "metadata": {
        "id": "MqeiCyEapRRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    \"units_1\": 64,\n",
        "    \"units_2\": 32,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"final_activation\": \"linear\"\n",
        "}"
      ],
      "metadata": {
        "id": "tvOo7lvKpRVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_config = {\n",
        "    \"loss\": \"mean_squared_error\",\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"metrics\": [\n",
        "        \"mse\",\n",
        "        \"mae\",\n",
        "        \"mape\",\n",
        "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "fCHqM8vTpRbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_config = {\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 32,\n",
        "    \"sequence_length\": 16\n",
        "}"
      ],
      "metadata": {
        "id": "fubYIc_qpO_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IkExEFUypggV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_mess   = os.path.join(folder_import, name_Messwerte)\n",
        "path_vorher = os.path.join(folder_import, name_Vorhersage)\n",
        "\n",
        "df_mess   = pd.read_csv(path_mess)\n",
        "df_vorher = pd.read_csv(path_vorher)"
      ],
      "metadata": {
        "id": "-LRq7U37pkqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_cols = [c for c in [\"Observation_period\", \"time\", \"timestamp\", \"Datetime\"] if c in df_mess.columns]\n",
        "assert len(time_cols) >= 1, \"Keine Zeitspalte in Messdaten gefunden – bitte anpassen.\"\n",
        "tcol = time_cols[0]\n",
        "df_mess[tcol] = pd.to_datetime(df_mess[tcol])\n",
        "\n",
        "if tcol in df_vorher.columns:\n",
        "    df_vorher[tcol] = pd.to_datetime(df_vorher[tcol])"
      ],
      "metadata": {
        "id": "T-0KodleplxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df_mess, df_vorher, on=tcol, how=\"inner\", suffixes=(\"\", \"_f\"))\n",
        "df = df.sort_values(tcol).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "X9JqA3nypnmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_X = [c for c in [\"GHI\", \"ghi\", \"Clear_sky_GHI\", \"Dif\", \"Dir\", \"SZA\", \"BHI\", \"UVA\", \"UVB\"]\n",
        "               if c in df.columns]\n",
        "columns_X = candidate_X  # <- hier bei Bedarf erweitern/ändern\n",
        "columns_y = [\"UVI\"] if \"UVI\" in df.columns else [\"UV\"]  # wähle 'UVI' oder ersatzweise 'UV'\n",
        "\n",
        "print(\"Features (X):\", columns_X)\n",
        "print(\"Target (y):\", columns_y)"
      ],
      "metadata": {
        "id": "U7YtfP3bpq7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_length = len(df)\n",
        "train_size   = round(total_length * 0.80)\n",
        "val_size     = round(total_length * 0.10)\n",
        "test_size    = total_length - train_size - val_size  # restliche 10%\n",
        "\n",
        "train_df = df.iloc[:train_size].copy()\n",
        "val_df   = df.iloc[train_size : train_size + val_size].copy()\n",
        "test_df  = df.iloc[train_size + val_size :].copy()\n",
        "\n",
        "print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
      ],
      "metadata": {
        "id": "PtVqa5Spprmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "train_df[columns_X] = scaler_X.fit_transform(train_df[columns_X])\n",
        "train_df[columns_y] = scaler_y.fit_transform(train_df[columns_y])\n",
        "\n",
        "val_df[columns_X] = scaler_X.transform(val_df[columns_X])\n",
        "val_df[columns_y] = scaler_y.transform(val_df[columns_y])\n",
        "\n",
        "test_df[columns_X] = scaler_X.transform(test_df[columns_X])\n",
        "test_df[columns_y] = scaler_y.transform(test_df[columns_y])"
      ],
      "metadata": {
        "id": "HgNLmW3wpt9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(scaler_X, scaler_x_path)\n",
        "joblib.dump(scaler_y, scaler_y_path)"
      ],
      "metadata": {
        "id": "bNV1UJbJpw1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_sequences(df_in: pd.DataFrame, X_cols, y_cols, seq_len: int):\n",
        "    X_seq, y_seq = [], []\n",
        "    values_X = df_in[X_cols].values\n",
        "    values_y = df_in[y_cols].values\n",
        "    for i in range(len(df_in) - seq_len):\n",
        "        X_seq.append(values_X[i:i+seq_len])\n",
        "        # One-step-ahead: nächster Zeitpunkt als Ziel\n",
        "        y_seq.append(values_y[i+seq_len])\n",
        "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
        "\n",
        "SEQ_LEN = fit_config[\"sequence_length\"]\n",
        "\n",
        "X_train, y_train = make_sequences(train_df, columns_X, columns_y, SEQ_LEN)\n",
        "X_val,   y_val   = make_sequences(val_df,   columns_X, columns_y, SEQ_LEN)\n",
        "X_test,  y_test  = make_sequences(test_df,  columns_X, columns_y, SEQ_LEN)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "pfGFjr3qp054"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_test.reshape(X_test.shape[0], -1)).to_csv(testdata_path_X, index=False)\n",
        "pd.DataFrame(y_test, columns=columns_y).to_csv(testdata_path_Y, index=False)"
      ],
      "metadata": {
        "id": "GR9pBgVxp1aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = len(columns_X)\n",
        "n_targets  = len(columns_y)\n",
        "\n",
        "inputs = keras.Input(shape=(SEQ_LEN, n_features))\n",
        "x = layers.LSTM(model_config[\"units_1\"], return_sequences=True)(inputs)\n",
        "x = layers.Dropout(model_config[\"dropout_rate\"])(x)\n",
        "x = layers.LSTM(model_config[\"units_2\"])(x)\n",
        "x = layers.Dropout(model_config[\"dropout_rate\"])(x)\n",
        "outputs = layers.Dense(n_targets, activation=model_config[\"final_activation\"])(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"lstm_uv_forecast\")\n",
        "model.compile(\n",
        "    loss=training_config[\"loss\"],\n",
        "    optimizer=training_config[\"optimizer\"],\n",
        "    metrics=training_config[\"metrics\"]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pWx0TTu3p32z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "2epqZomEp6mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_run = wandb.init(\n",
        "    project=\"uv-forecasting\",\n",
        "    name=f\"lstm-{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "    config={\n",
        "        \"model_config\": model_config,\n",
        "        \"training_config\": {\n",
        "            \"loss\": training_config[\"loss\"],\n",
        "            \"optimizer\": \"adam\",\n",
        "            \"metrics\": [\"mse\", \"mae\", \"mape\", \"rmse\"]\n",
        "        },\n",
        "        \"fit_config\": fit_config,\n",
        "        \"n_features\": n_features,\n",
        "        \"n_targets\": n_targets,\n",
        "        \"sequence_length\": SEQ_LEN,\n",
        "        \"split_sizes\": {\n",
        "            \"train\": train_size, \"val\": val_size, \"test\": test_size\n",
        "        },\n",
        "        \"columns_X\": columns_X,\n",
        "        \"columns_y\": columns_y\n",
        "    }\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Callbacks (inkl. W&B)\n",
        "# =========================\n",
        "callbacks = [\n",
        "    WandbCallback(save_model=False),  # wir speichern unten manuell\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_rmse\", patience=5, mode=\"min\", restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=weights_path, save_weights_only=True,\n",
        "        monitor=\"val_rmse\", mode=\"min\", save_best_only=True, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.CSVLogger(text_file_path.replace(\".txt\", \"_history.csv\"))\n",
        "]"
      ],
      "metadata": {
        "id": "XoOygyu6p8Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=fit_config[\"epochs\"],\n",
        "    batch_size=fit_config[\"batch_size\"],\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "nfM_FKPjqFR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = model.evaluate(X_test, y_test, verbose=0)\n",
        "metrics_names = model.metrics_names\n",
        "results_dict = {name: float(val) for name, val in zip(metrics_names, eval_results)}\n",
        "print(\"Test-Ergebnisse:\", results_dict)"
      ],
      "metadata": {
        "id": "z6w-XHgPqGc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log({f\"test/{k}\": v for k, v in results_dict.items()})"
      ],
      "metadata": {
        "id": "xd_yKcjHqJIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(weights_path):\n",
        "    model.load_weights(weights_path)"
      ],
      "metadata": {
        "id": "JwOZjDJ3qKmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "J1OfIxW8qMVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_file_path, \"w\") as f:\n",
        "    f.write(\"=== LSTM UV-Forecasting – Ergebnisse ===\\n\")\n",
        "    f.write(f\"Zeit: {dt.datetime.now()}\\n\\n\")\n",
        "    f.write(\"Konfigurationen:\\n\")\n",
        "    f.write(f\"model_config: {model_config}\\n\")\n",
        "    f.write(f\"training_config: {training_config}\\n\")\n",
        "    f.write(f\"fit_config: {fit_config}\\n\")\n",
        "    f.write(f\"Features (X): {columns_X}\\nZiel (y): {columns_y}\\n\\n\")\n",
        "    f.write(\"Test-Performance:\\n\")\n",
        "    for k, v in results_dict.items():\n",
        "        f.write(f\"  {k}: {v:.6f}\\n\")\n",
        "    f.write(\"\\nPfade:\\n\")\n",
        "    f.write(f\"  model_path:   {model_path}\\n\")\n",
        "    f.write(f\"  weights_path: {weights_path}\\n\")\n",
        "    f.write(f\"  test_X_csv:   {testdata_path_X}\\n\")\n",
        "    f.write(f\"  test_Y_csv:   {testdata_path_Y}\\n\")\n",
        "    f.write(f\"  scaler_X:     {scaler_x_path}\\n\")\n",
        "    f.write(f\"  scaler_y:     {scaler_y_path}\\n\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ZLdirqXzqO1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}