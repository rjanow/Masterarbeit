{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj1LGchaY4PcMgLTyOL+LY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjanow/Masterarbeit/blob/main/Modeling_and_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "0Ng7WlqRF6Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In diesem Skript wird ein erstes Modell erzeugt, um aus den gemssenen Globalstrahlungsdaten den UVI zu berechen."
      ],
      "metadata": {
        "id": "AsUt2K5PFuQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verbinden mit der Google-Drive\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN5x7YhZ99QP",
        "outputId": "b061ba53-ae7d-4a72-cc24-515402441469"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XgnNp1CjFzPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSK4Ns8Op4YG",
        "outputId": "ed71e882-cad6-4894-c02c-97065c82ed6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "L1rcvDzU-F-w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pfad zur CSV-Datei auf Google Drive\n",
        "name_Messwerte = 'Messdaten_CAMS_GHI.csv'\n",
        "name_Vorhersage = 'Vorhersagedaten_CAMS_VarIdx.csv'\n",
        "folder_import = '/content/drive/My Drive/Colab_Notebooks/Clean_Data/'"
      ],
      "metadata": {
        "id": "yBFyA7hw9-XT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Messdaten\n",
        "df_Messdaten = pd.read_csv(folder_import + name_Messwerte)"
      ],
      "metadata": {
        "id": "1RAsBy3qGHTE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der Vorhersagedaten\n",
        "df_Vorhersage = pd.read_csv(folder_import + name_Vorhersage)"
      ],
      "metadata": {
        "id": "t1qhUxgIUU3v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konvertiere die Zeitspalten in ein gemeinsames Format und führe einen Merge der Datensätze durch\n",
        "df_Messdaten['Datetime'] = pd.to_datetime(df_Messdaten['Datetime'])\n",
        "df_Vorhersage['Datetime'] = pd.to_datetime(df_Vorhersage['Datetime'])"
      ],
      "metadata": {
        "id": "ETDBeb_894PE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Messdaten.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCdeBkhdUqUJ",
        "outputId": "9147aa4f-21e2-4a79-ecad-1a99520955ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Datetime', 'Observation_period', 'Clear_sky_GHI', 'Clear_sky_BHI',\n",
              "       'GHI', 'BHI', 'UVI', 'UVA', 'UVB', 'erythem', 'Datum', 'Uhrzeit',\n",
              "       'Messzeitpunkt', 'ghi', 'Dif', 'Glo_SPLite', 'Dir', 'Temp',\n",
              "       'DiffGreater2', 'SZA', 'time_sin', 'time_cos', 'date_sin', 'date_cos',\n",
              "       'Date', 'Hour'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevante Spalten\n",
        "indipendent_variablen = ['ghi', 'SZA', 'time_sin', 'time_cos', 'date_sin', 'date_cos']\n",
        "dependent_variablen = ['UVI']\n",
        "\n",
        "columns = indipendent_variablen + dependent_variablen"
      ],
      "metadata": {
        "id": "KG0T5leibAVE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diese Liste enthält die Spaltennamen der Merkmale, die als Inputs verwendet werden."
      ],
      "metadata": {
        "id": "Zg-aeY05ULXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying a scaler for regression\n",
        "MMS = MinMaxScaler()\n",
        "df_Messdaten[columns] = MMS.fit_transform(df_Messdaten[columns])"
      ],
      "metadata": {
        "id": "bQvT2EKj-mJD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die unabhängigen Variablen werden durch den MinMaxScaler skaliert."
      ],
      "metadata": {
        "id": "JfnYgQ2_UHbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting in training and testing samples\n",
        "training_size = round(len(df_Messdaten) * 0.80)\n",
        "train_data = df_Messdaten[columns][:training_size]\n",
        "test_data  = df_Messdaten[columns][training_size:]\n",
        "\n",
        "print(train_data, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VEGIoX8kavw",
        "outputId": "58a2f347-0f7c-4816-e406-be5909df1310"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ghi       SZA  time_sin  time_cos  date_sin  date_cos       UVI\n",
            "0      0.449763  0.394655  0.969096  0.403006  0.641161  0.020303  0.281919\n",
            "1      0.452447  0.390193  0.969096  0.403006  0.641161  0.020303  0.281919\n",
            "2      0.455624  0.385734  0.967568  0.397968  0.641161  0.020303  0.288240\n",
            "3      0.458118  0.381277  0.966004  0.392947  0.641161  0.020303  0.290191\n",
            "4      0.463850  0.376825  0.964405  0.387943  0.641161  0.020303  0.297739\n",
            "...         ...       ...       ...       ...       ...       ...       ...\n",
            "77381  0.342308  0.574718  0.058526  0.326979  0.971797  0.334079  0.093193\n",
            "77382  0.152062  0.579150  0.056495  0.331739  0.971797  0.334079  0.078514\n",
            "77383  0.125504  0.583587  0.054497  0.336521  0.971797  0.334079  0.070488\n",
            "77384  0.108314  0.588028  0.052533  0.341323  0.971797  0.334079  0.067234\n",
            "77385  0.095241  0.592473  0.050603  0.346147  0.971797  0.334079  0.062044\n",
            "\n",
            "[77386 rows x 7 columns]             ghi       SZA  time_sin  time_cos  date_sin  date_cos       UVI\n",
            "77386  0.079275  0.596921  0.048707  0.350992  0.971797  0.334079  0.058865\n",
            "77387  0.069880  0.601373  0.046846  0.355856  0.971797  0.334079  0.055703\n",
            "77388  0.071556  0.605828  0.045019  0.360741  0.971797  0.334079  0.054544\n",
            "77389  0.079093  0.610286  0.043227  0.365644  0.971797  0.334079  0.054791\n",
            "77390  0.114911  0.614747  0.041470  0.370567  0.971797  0.334079  0.054480\n",
            "...         ...       ...       ...       ...       ...       ...       ...\n",
            "96727  0.188603  0.718702  0.999315  0.648583  0.130304  0.163493  0.035933\n",
            "96728  0.189374  0.714245  0.999524  0.643211  0.130304  0.163493  0.036573\n",
            "96729  0.174686  0.709785  0.999695  0.637837  0.130304  0.163493  0.036784\n",
            "96730  0.174665  0.705323  0.999829  0.632461  0.130304  0.163493  0.037088\n",
            "96731  0.137522  0.700858  0.999924  0.627084  0.130304  0.163493  0.036570\n",
            "\n",
            "[19346 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_validation_data(X_val, y_val, save_path, file_name='validation_data.csv'):\n",
        "    \"\"\"\n",
        "    Speichert den Validierungsdatensatz als CSV-Datei.\n",
        "\n",
        "    Parameters:\n",
        "    - X_val: numpy.ndarray, Eingabedaten des Validierungsdatensatzes (3D-Array: Anzahl der Sequenzen x Sequenzlänge x Features)\n",
        "    - y_val: numpy.ndarray, Zielwerte des Validierungsdatensatzes (1D-Array)\n",
        "    - save_path: str, Verzeichnis, in dem die Datei gespeichert werden soll\n",
        "    - file_name: str, Name der CSV-Datei (Standard: 'validation_data.csv')\n",
        "\n",
        "    Returns:\n",
        "    - full_path: str, vollständiger Pfad der gespeicherten Datei\n",
        "    \"\"\"\n",
        "    # Stelle sicher, dass das Verzeichnis existiert\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Konvertiere X_val in ein flaches Format\n",
        "    X_val_flat = X_val.reshape(X_val.shape[0], -1)  # (Anzahl der Sequenzen, Sequenzlänge * Features)\n",
        "\n",
        "    # Kombiniere X_val und y_val in einen DataFrame\n",
        "    validation_data = pd.DataFrame(X_val_flat)\n",
        "    validation_data['y_val'] = y_val  # Zielwerte hinzufügen\n",
        "\n",
        "    # Speichere die Datei als CSV\n",
        "    full_path = os.path.join(save_path, file_name)\n",
        "    validation_data.to_csv(full_path, index=False)\n",
        "\n",
        "    print(f\"Validation data saved to: {full_path}\")\n",
        "    return full_path"
      ],
      "metadata": {
        "id": "TSlhwIKT1YTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence(dataset, sequence_len):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for start_idx in range(len(dataset) - sequence_len):\n",
        "        stop_idx = start_idx + sequence_len\n",
        "        # Sequenz (Fenster mit Länge sequence_len)\n",
        "        sequences.append(dataset.iloc[start_idx:stop_idx].values)\n",
        "        # Zielwert (nur die Zielspalte)\n",
        "        labels.append(dataset.iloc[stop_idx]['UVI'])  # 'UVI' ist die Zielspalte\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "GMgoe7wrkn2H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier werden die Eingabedaten (X_train und X_val) als Sequenzen mit einer Länge von 100 Schritten erstellt. Die endgültige Dimension der Input-Daten für das Modell ist:\n",
        "\n",
        "X_train.shape = (77286, 100, 7)\n",
        "Dabei:\n",
        "77286: Anzahl der Trainingssequenzen\n",
        "100: Zeitfenster (Sequenzlänge)\n",
        "7: Anzahl der Features (Input-Parameter)"
      ],
      "metadata": {
        "id": "jxC1-WlzUETK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen des Trainigs- und Validierungsdatensatzes\n",
        "X_train, y_train = create_sequence(train_data,100)\n",
        "X_val, y_val = create_sequence(test_data,100)"
      ],
      "metadata": {
        "id": "wYi5BLd3kqn7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train:', X_train.shape, '\\n y_train:', y_train.shape, '\\n X_val:', X_val.shape, '\\n y_val:', y_val.shape)"
      ],
      "metadata": {
        "id": "_wf7FCXeziru",
        "outputId": "a6d8219e-5f26-43cc-b540-26d8a87f0722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (77286, 100, 7) \n",
            " y_train: (77286,) \n",
            " X_val: (19246, 100, 7) \n",
            " y_val: (19246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating LSTM for regression\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 64, return_sequences=True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(units = 32))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58LU_zfHkwY-",
        "outputId": "1813b7fc-67d7-485d-b8d5-be255ff47e4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 4, validation_data = (X_val, y_val), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln2ZkEBrkxY6",
        "outputId": "9c6f76b5-e38f-4fde-d635-114bd51235dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 123ms/step - loss: 0.0023 - mean_absolute_error: 0.0254 - val_loss: 0.0017 - val_mean_absolute_error: 0.0235\n",
            "Epoch 2/4\n",
            "\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 119ms/step - loss: 5.3585e-04 - mean_absolute_error: 0.0129 - val_loss: 0.0015 - val_mean_absolute_error: 0.0190\n",
            "Epoch 3/4\n",
            "\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 122ms/step - loss: 4.6414e-04 - mean_absolute_error: 0.0115 - val_loss: 0.0015 - val_mean_absolute_error: 0.0190\n",
            "Epoch 4/4\n",
            "\u001b[1m2416/2416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 121ms/step - loss: 4.3228e-04 - mean_absolute_error: 0.0108 - val_loss: 0.0015 - val_mean_absolute_error: 0.0187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Speichern des Modells in einem Verzeichnis in Google Drive\n",
        "\n",
        "model_dir = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/'\n",
        "model_name = 'full_model.keras'\n",
        "model_path = os.path.join(model_dir, model_name)\n",
        "model.save(model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK6O39CTg2wO",
        "outputId": "a98cf4da-2b66-44ae-810c-dfd8c246e234"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/My Drive/Colab_Notebooks/LSTM_Model/full_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gewichte speichern\n",
        "weights_dir = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/'\n",
        "weights_name = 'model_weights.weights.h5'\n",
        "weights_path = os.path.join(weights_dir, weights_name)\n",
        "model.save_weights(weights_path)\n",
        "\n",
        "print(f\"weights saved to: {weights_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy9-YvY5g83p",
        "outputId": "b443fea6-4435-4311-a4c0-563f57a96251"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights saved to: /content/drive/My Drive/Colab_Notebooks/LSTM_Model/model_weights.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ27xgctxO3P",
        "outputId": "e1aa2a7e-042a-4d41-e3e4-8f42c9348e1c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19246, 100, 7) (19246,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Konvertiere X_val in ein flaches Format\n",
        "X_val_flat = X_val.reshape(X_val.shape[0], -1)  # (Anzahl der Sequenzen, Sequenzlänge * Anzahl der Features)\n",
        "\n",
        "# Kombiniere X_val und y_val in einen DataFrame\n",
        "validation_data = pd.DataFrame(X_val_flat)\n",
        "validation_data['y_val'] = y_val.flatten()  # Füge die Zielwerte hinzu\n",
        "\n",
        "validation_data_path = '/content/drive/My Drive/Colab_Notebooks/LSTM_Model/validation_data.csv'\n",
        "validation_data.to_csv(validation_data_path, index=False)"
      ],
      "metadata": {
        "id": "bvcUD_lYmQAh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_flat_path = save_validation_data(\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    save_path='/content/drive/My Drive/Colab_Notebooks/LSTM_Model',\n",
        "    file_name='validation_data.csv'\n",
        ")"
      ],
      "metadata": {
        "id": "YdLm_G5a1bLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_val_flat:\", X_val_flat.shape)\n",
        "print(\"Length of y_val:\", len(y_val.flatten()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkBqWAtCtI1A",
        "outputId": "bf88ade2-9993-4939-ad08-8e0fd7ce47f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_val_flat: (19246, 700)\n",
            "Length of y_val: 19246\n"
          ]
        }
      ]
    }
  ]
}